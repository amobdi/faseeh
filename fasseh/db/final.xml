<aiml version="1.0.1" encoding="UTF-8">
	<category>
		<pattern>* WHAT * INHERITANCE MECHANISM * SEMANTIC NETWORKS * IMPLEMENTS *</pattern>
		<template>The inheritance mechanism in semantic networks implements the overriding of defaults in a simple and natural way.</template>
	</category>
	<category>
		<pattern>* WHAT * NONMONOTONICITY *</pattern>
		<template>For example, when one sees a car parked on the street, one is normally willing to believe that it has four wheels even though only three are visible.
 Now, probability theory can certainly provide a conclusion that the fourth wheel exists with high probability, yet, for most people, the possibility of the car's not having four wheels does not arise unless some new evidence presents itself.
 Thus, it seems that the four-wheel conclusion is reached by default, in the absence of any reason to doubt it.
 If new evidence arrives-for example, if one sees the owner carrying a wheel and notices that the car is jacked up-then the conclusion can be retracted.
 This kind of reasoning is said to exhibit nonmonotonicity, because the set of beliefs does not grow monotonically over time as new evidence arrives.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * NONMONOTONICITY *</pattern>
		<template>For example, when one sees a car parked on the street, one is normally willing to believe that it has four wheels even though only three are visible.
 Now, probability theory can certainly provide a conclusion that the fourth wheel exists with high probability, yet, for most people, the possibility of the car's not having four wheels does not arise unless some new evidence presents itself.
 Thus, it seems that the four-wheel conclusion is reached by default, in the absence of any reason to doubt it.
 If new evidence arrives-for example, if one sees the owner carrying a wheel and notices that the car is jacked up-then the conclusion can be retracted.
 This kind of reasoning is said to exhibit nonmonotonicity, because the set of beliefs does not grow monotonically over time as new evidence arrives.</template>
	</category>
	<category>
		<pattern>* WHAT * SIMPLE INTROSPECTION * SUGGESTS *</pattern>
		<template>Simple introspection suggests that these failures of monotonicity are widespread in commonsense reasoning.</template>
	</category>
	<category>
		<pattern>* EXPLAIN * EVIDENCE * ARRIVES * CONCLUSION * RETRACTED *</pattern>
		<template>because the set of beliefs does not grow monotonically over time as new evidence arrives.</template>
	</category>
	<category>
		<pattern>* EXPLAIN * EXHIBIT * NONMONOTONICITY *</pattern>
		<template>because the set of beliefs does not grow monotonically over time as new evidence arrives.</template>
	</category>
	<category>
		<pattern>* WHY * NONMONOTONIC LOGICS * DEVISED *</pattern>
		<template>Nonmonotonic logics have been devised with modified notions of truth and entailment in order to capture the behaviour of nonmonotonicity.</template>
	</category>
	<category>
		<pattern>* WHAT * IDEA * CIRCUMSCRIPTION *</pattern>
		<template>The idea is to specify particular predicates that are assumed to be "as false as possible"-that is, false for every object except those for which they are known to be true.</template>
	</category>
	<category>
		<pattern>* WHAT * CIRCUMSCRIPTION *</pattern>
		<template>The idea is to specify particular predicates that are assumed to be "as false as possible"-that is, false for every object except those for which they are known to be true.</template>
	</category>
	<category>
		<pattern>* WHAT * MODEL PREFERENCE LOGIC *</pattern>
		<template>It is the logic where a sentence is entailed (with default status) if it is true in all preferred models of the KB, as opposed to the requirement of truth in all models in classical logic.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * MODEL PREFERENCE LOGIC *</pattern>
		<template>Circumscription</template>
	</category>
	<category>
		<pattern>* WHEN * CIRCUMSCRIPTION * MODEL * PREFERRED * ANOTHER *</pattern>
		<template>For circumscription, one model is preferred to another if it has fewer abnormal objects.</template>
	</category>
	<category>
		<pattern>* WHEN * CLOSED-WORLD ASSUMPTION * MODEL * PREFERRED * ANOTHER *</pattern>
		<template>For the closed-world assumption, one model is preferred to another if it has fewer true atoms-that is, preferred models are minimal models.</template>
	</category>
	<category>
		<pattern>* WHAT * NIXON DIAMOND *</pattern>
		<template>The standard example for which multiple inheritance is problematic is called the Nixon diamond.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * MULTIPLE INHERITANCE * PROBLEMATIC *</pattern>
		<template>The standard example for which multiple inheritance is problematic is called the "Nixon diamond."</template>
	</category>
	<category>
		<pattern>* NIXON DIAMOND * ARISES *</pattern>
		<template>It arises from the observation that Richard Nixon was both a Quaker (and hence by default a pacifist) and a Republican (and hence by default not a pacifist).</template>
	</category>
	<category>
		<pattern>* WHEN * USE * PRIORITIZED CIRCUMSCRIPTION *</pattern>
		<template>Prioritized schemes exist in which some default rules can be given precedence over others, allowing some ambiguities to be resolved.
 For example to assert that religious beliefs take precedence over political beliefs, we can use a formalism called prioritized circumscription.</template>
	</category>
	<category>
		<pattern>* WHAT * PRIORITIZED CIRCUMSCRIPTION *</pattern>
		<template>It is a formalism used to to give preference to models to minimize a certain preferred model.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * MODEL PREFERENCE LOGIC *</pattern>
		<template>Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* WHAT * EXAMPLE * MODEL PREFERENCE LOGIC *</pattern>
		<template>Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* WHAT * DEFAULT LOGIC *</pattern>
		<template>Default logic is a formalism in which default rules can be written to generate continuous nonmonotonic conclusions and it is given by P : J1, .
 .
 .
 , Jn/C , where P is called the prerequisite, C is the conclusion, and Ji are the justifications.</template>
	</category>
	<category>
		<pattern>* WHAT * DEFAULT RULES *</pattern>
		<template>They are rules used to generate continuous nonmonotonic conclusions and it is given by P : J1, .
 .
 .
 , Jn/C where P is called the prerequisite, C is the conclusion, and Ji are the justifications</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * DEFAULT RULES *</pattern>
		<template>Bird(x) : Flies(x)/Flies(x)</template>
	</category>
	<category>
		<pattern>* WHAT * DEFAULT LOGIC * CONSIST *</pattern>
		<template>P : J1, .
 .
 .
 , Jn/C Where P is called the prerequisite, C is the conclusion, and Ji are the justifications, if any one of them can be proven false, then the conclusion cannot be drawn.
 Any variable that appears in Ji or C must also appear in P.</template>
	</category>
	<category>
		<pattern>* WHAT * EXTENSION * DEFAULT THEORY *</pattern>
		<template>We define the notion of an extension of a default theory to be a maximal set of consequences of the theory.</template>
	</category>
	<category>
		<pattern>* WHAT * EXTENSION *</pattern>
		<template>We define the notion of an extension of a default theory to be a maximal set of consequences of the theory.</template>
	</category>
	<category>
		<pattern>* EXTENSION * CONSISTS *</pattern>
		<template>An extension S consists of the original known facts and a set of conclusions from the default rules, such that no additional conclusions can be drawn from S and the justifications of every default conclusion in S are consistent with S.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * UNRESOLVED QUESTIONS *</pattern>
		<template>if "Cars have four wheels" is false, what does it mean to have it in one's knowledge base? What is a good set of default rules to have? If we cannot decide, for each rule separately, whether it belongs in our knowledge base, then we have a serious problem of nonmodularity.</template>
	</category>
	<category>
		<pattern>* PRIORITIZED SCHEMES * EXIST *</pattern>
		<template>Prioritized schemes exist in which some default rules can be given precedence over others, allowing some ambiguities to be resolved.</template>
	</category>
	<category>
		<pattern>* WHEN * NONMONOTONIC LOGICS * PROPOSED *</pattern>
		<template>Since 1980.</template>
	</category>
	<category>
		<pattern>* WHEN * PROBLEM * NONMODULARITY *</pattern>
		<template>If we cannot decide, for each rule separately, whether it belongs in our knowledge base.</template>
	</category>
	<category>
		<pattern>* WHAT * HARDEST * ISSUE * DEFAULT REASONING *</pattern>
		<template>How can beliefs that have default status be used to make decisions is the hardest issue for default reasoning.</template>
	</category>
	<category>
		<pattern>* WHY * COMPARE * STRENGTHS * BELIEF * OUTCOMES * DIFFERENT * ACTIONS * COSTS * WRONG * DECISION *</pattern>
		<template>Because decisions often involve tradeoffs.</template>
	</category>
	<category>
		<pattern>* WHY * COMPARE * COSTS * WRONG * DECISION *</pattern>
		<template>Because decisions often involve tradeoffs.</template>
	</category>
	<category>
		<pattern>* WHY * COMPARE * STRENGTHS * BELIEF * OUTCOMES * DIFFERENT * ACTIONS *</pattern>
		<template>Because decisions often involve tradeoffs.</template>
	</category>
	<category>
		<pattern>* DECISIONS * INVOLVE * TRADEOFFS *</pattern>
		<template>One needs to compare the strengths of belief in the outcomes of different actions, and the costs of making a wrong decision.</template>
	</category>
	<category>
		<pattern>* SAME * DECISIONS * MADE * REPEATEDLY *</pattern>
		<template>It is possible to interpret default rules as "threshold probability" statements.</template>
	</category>
	<category>
		<pattern>* WHEN * THRESHOLD PROBABILITY *</pattern>
		<template>In cases where the same kinds of decisions are being made repeatedly.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * THRESHOLD PROBABILITY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes-for example, when one is driving a heavily laden truck down a steep mountain road-the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* DEFAULT REASONING * PROBABILITY THEORY * UTILITY THEORY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes-for example, when one is driving a heavily laden truck down a steep mountain road-the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* DEFAULT REASONING * PROBABILITY THEORY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes-for example, when one is driving a heavily laden truck down a steep mountain road-the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* DEFAULT REASONING * UTILITY THEORY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes-for example, when one is driving a heavily laden truck down a steep mountain road-the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* WHAT * BELIEF REVISION *</pattern>
		<template>Many of the inferences drawn by a knowledge representation system will have only default status, rather than being absolutely certain.
 Inevitably, some of these inferred facts will turn out to be wrong and will have to be retracted in the face of new information and this process is called belief revision.</template>
	</category>
	<category>
		<pattern>* WHEN * BELIEF UPDATE *</pattern>
		<template>It occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.</template>
	</category>
	<category>
		<pattern>* BELIEF REVISION * CONTRAST * BELIEF UPDATE *</pattern>
		<template>Belief revision is often contrasted with belief update, which occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.
 Belief update combines belief revision with reasoning about time and change.</template>
	</category>
	<category>
		<pattern>* WHY * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>Truth maintenance systems are designedto handle exactly some kinds of complications suach as : For example, the implication P -> Q might have been used to add Q.
 The obvious "solution"-retracting all sentences inferred from P-fails because such sentences may have other justifications besides P.
 For example, if R and R -> Q are also in the KB, then Q does not have to be removed after all.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>Truth maintenance systems are designedto handle exactly some kinds of complications suach as : For example, the implication P -> Q might have been used to add Q.
 The obvious "solution"-retracting all sentences inferred from P-fails because such sentences may have other justifications besides P.
 For example, if R and R -> Q are also in the KB, then Q does not have to be removed after all.</template>
	</category>
	<category>
		<pattern>* WHY * TMS *</pattern>
		<template>Truth maintenance systems are designedto handle exactly some kinds of complications suach as : For example, the implication P -> Q might have been used to add Q.
 The obvious "solution"-retracting all sentences inferred from P-fails because such sentences may have other justifications besides P.
 For example, if R and R -> Q are also in the KB, then Q does not have to be removed after all.</template>
	</category>
	<category>
		<pattern>* APPROACH * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.
 This is simple, and it guarantees that the knowledge base will be consistent.</template>
	</category>
	<category>
		<pattern>* EFFICIENT * APPROACH * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>An efficient approach JTMS is the justification-based truth maintenance system, or JTMS.
 In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.</template>
	</category>
	<category>
		<pattern>* WHAT * JTMS *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.</template>
	</category>
	<category>
		<pattern>* WHAT * JUSTIFICATION-BASED TRUTH * MAINTENANCE SYSTEM *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.</template>
	</category>
	<category>
		<pattern>* WHAH * JUSTIFICATION-BASED TRUTH * MAINTENANCE SYSTEM * ASSUME *</pattern>
		<template>The JTMS assumes that sentences that are considered once will probably be considered again, so rather than deleting a sentence from the knowledge base entirely when it loses all justifications, we merely mark the sentence as being out of the knowledge base.</template>
	</category>
	<category>
		<pattern>* WHAT * JTMS * ASSUME *</pattern>
		<template>The JTMS assumes that sentences that are considered once will probably be considered again, so rather than deleting a sentence from the knowledge base entirely when it loses all justifications, we merely mark the sentence as being out of the knowledge base.</template>
	</category>
	<category>
		<pattern>* HOW * JTMS * RETAIN * INFERENCE CHAINS *</pattern>
		<template>If a subsequent assertion restores one of the justifications, then we mark the sentence as being back in, and n this way, the JTMS retains all the inference chains that it uses and need not rederive sentences when a justification becomes valid again.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * JUSTIFICATION *</pattern>
		<template>If the knowledge base already contains P -> Q, then TELL(P) will cause Q to be added with the justification {P, P -> Q}.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * TMSs *</pattern>
		<template>For example, that the Romanian Olympic Committee is choosing sites for the swimming, athletics, and equestrian events at the 2048 Games to be held in Romania.
 For example, let the first hypothesis be Site(Swimming, Pitesti ), Site(Athletics,Bucharest ), and Site(Equestrian, Arad).
 A great deal of reasoning must then be done to work out the logistical consequences and hence the desirability of this selection.
 If we want to consider Site(Athletics, Sibiu) instead, the TMS avoids the need to start again from scratch.
 Instead, we simply retract Site(Athletics,Bucharest ) and assert Site(Athletics, Sibiu) and the TMS takes care of the necessary revisions.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * TMS *</pattern>
		<template>For example, that the Romanian Olympic Committee is choosing sites for the swimming, athletics, and equestrian events at the 2048 Games to be held in Romania.
 For example, let the first hypothesis be Site(Swimming, Pitesti ), Site(Athletics,Bucharest ), and Site(Equestrian, Arad).
 A great deal of reasoning must then be done to work out the logistical consequences and hence the desirability of this selection.
 If we want to consider Site(Athletics, Sibiu) instead, the TMS avoids the need to start again from scratch.
 Instead, we simply retract Site(Athletics,Bucharest ) and assert Site(Athletics, Sibiu) and the TMS takes care of the necessary revisions.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>For example, that the Romanian Olympic Committee is choosing sites for the swimming, athletics, and equestrian events at the 2048 Games to be held in Romania.
 For example, let the first hypothesis be Site(Swimming, Pitesti ), Site(Athletics,Bucharest ), and Site(Equestrian, Arad).
 A great deal of reasoning must then be done to work out the logistical consequences and hence the desirability of this selection.
 If we want to consider Site(Athletics, Sibiu) instead, the TMS avoids the need to start again from scratch.
 Instead, we simply retract Site(Athletics,Bucharest ) and assert Site(Athletics, Sibiu) and the TMS takes care of the necessary revisions.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * TRUTH MAINTENANCE SYSTEMS *</pattern>
		<template>For example, that the Romanian Olympic Committee is choosing sites for the swimming, athletics, and equestrian events at the 2048 Games to be held in Romania.
 For example, let the first hypothesis be Site(Swimming, Pitesti ), Site(Athletics,Bucharest ), and Site(Equestrian, Arad).
 A great deal of reasoning must then be done to work out the logistical consequences and hence the desirability of this selection.
 If we want to consider Site(Athletics, Sibiu) instead, the TMS avoids the need to start again from scratch.
 Instead, we simply retract Site(Athletics,Bucharest ) and assert Site(Athletics, Sibiu) and the TMS takes care of the necessary revisions.</template>
	</category>
	<category>
		<pattern>* HOW * JUSTIFICATION-BASED TRUTH * MAINTENANCE SYSTEM * RETAIN * INFERENCE CHAINS *</pattern>
		<template>If a subsequent assertion restores one of the justifications, then we mark the sentence as being back in, and n this way, the JTMS retains all the inference chains that it uses and need not rederive sentences when a justification becomes valid again.</template>
	</category>
	<category>
		<pattern>* WHAT * TMS * HANDLE *</pattern>
		<template>It handles the retraction of incorrect information also TMSs can be used to speed up the analysis of multiple hypothetical situations, as it provides a mechanism for generating explanations.</template>
	</category>
	<category>
		<pattern>* WHAT * TMSS * HANDLE *</pattern>
		<template>It handles the retraction of incorrect information also TMSs can be used to speed up the analysis of multiple hypothetical situations, as it provides a mechanism for generating explanations.</template>
	</category>
	<category>
		<pattern>* WHAT * TRUTH MAINTENANCE SYSTEM * HANDLE *</pattern>
		<template>It handles the retraction of incorrect information also TMSs can be used to speed up the analysis of multiple hypothetical situations, as it provides a mechanism for generating explanations.</template>
	</category>
	<category>
		<pattern>* WHAT * ATMS *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* WHAT * ATMSS *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* WHAT * ASSUMPTION-BASED TRUTH * MAINTENANCE SYSTEM *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* WHAT * ASSUMPTION-BASED TRUTH * MAINTENANCE SYSTEM *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* WHAT * EXPLANATION * SENTENCE *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.</template>
	</category>
	<category>
		<pattern>* WHAT * EXPLANATION *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.</template>
	</category>
	<category>
		<pattern>* EXPLANATIONS * INCLUDE * ASSUMPTIONS *</pattern>
		<template>For example, one might not have enough information to prove that one's car won't start, but a reasonable explanation might include the assumption that the battery is dead.
 This, combined with knowledge of how cars operate, explains the observed nonbehavior.</template>
	</category>
	<category>
		<pattern>* WHAT * ASSUMPTIONS *</pattern>
		<template>Assumptions sentences are sentences that are not known to be true,</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * EXPLANATIONS * INCLUDE * ASSUMPTIONS *</pattern>
		<template>For example, one might not have enough information to prove that one's car won't start, but a reasonable explanation might include the assumption that the battery is dead.
 This, combined with knowledge of how cars operate, explains the observed nonbehavior.</template>
	</category>
	<category>
		<pattern>* COMPLEXITY * TRUTH MAINTENANCE SYSTEMS *</pattern>
		<template>The computational complexity of the truth maintenance problem is at least as great as that of propositional inference-that is, NP-hard.</template>
	</category>
	<category>
		<pattern>* COMPLEXITY * TMS *</pattern>
		<template>The computational complexity of the truth maintenance problem is at least as great as that of propositional inference-that is, NP-hard.</template>
	</category>
	<category>
		<pattern>* WHY * SITUATION CALCULUS * LIMITED * APPLICABILITY *</pattern>
		<template>Because it was designed to describe a world in which actions are discrete, instantaneous, and happen one at a time.</template>
	</category>
	<category>
		<pattern>* WHAT * SITUATION CALCULUS * DESIGNED TO *</pattern>
		<template>It was designed to describe a world in which actions are discrete, instantaneous, and happen one at a time.</template>
	</category>
	<category>
		<pattern>* WHAT * SITUATION CALCULUS * DESCRIBE *</pattern>
		<template>It was designed to describe a world in which actions are discrete, instantaneous, and happen one at a time.</template>
	</category>
	<category>
		<pattern>* WHICH REPRESENTATION * DESCRIBE * ACTIONS * DISCRETE * INSTANTANEOUS * ONE AT A TIME *</pattern>
		<template>It was designed to describe a world in which actions are discrete, instantaneous, and happen one at a time.</template>
	</category>
	<category>
		<pattern>* WHICH ACTIONS * SITUATION CALCULUS * DESCRIBE *</pattern>
		<template>It was designed to describe a world in which actions are discrete, instantaneous, and happen one at a time.</template>
	</category>
	<category>
		<pattern>* WHEN * SITUATION CALCULUS * SAY * TUB * EMPTY *</pattern>
		<template>Before the action.</template>
	</category>
	<category>
		<pattern>* WHEN * SITUATION CALCULUS * SAY * TUB * FULL *</pattern>
		<template>When the action is done.</template>
	</category>
	<category>
		<pattern>* WHAT * SITUATION CALCULUS * CAN * SAY *</pattern>
		<template>Situation calculus can say that the tub is empty before the action and full when the action is done.</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT CALCULUS * BASED ON *</pattern>
		<template>It is based on points of time.</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT CALCULUS *</pattern>
		<template>Formalism is based on points of time.</template>
	</category>
	<category>
		<pattern>* WHICH * FORMALISM * BASED ON * POINTS OF TIME *</pattern>
		<template>Event calculus.</template>
	</category>
	<category>
		<pattern>* HOW * FLUENTS * ACTIONS * DEFINED *</pattern>
		<template>Fluents and actions are defined with domain-specific axioms that are similar to successorstate axioms.</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT CALCULUS * REIFIES *</pattern>
		<template>Event calculus reifies fluents and events.</template>
	</category>
	<category>
		<pattern>* WHAT * REIFYING EVENTS * MAKE *</pattern>
		<template>By reifying events we make it possible to add any amount of arbitrary information about them.</template>
	</category>
	<category>
		<pattern>* WHAT * REIFYING EVENTS * ADD *</pattern>
		<template>By reifying events we make it possible to add any amount of arbitrary information about them.</template>
	</category>
	<category>
		<pattern>* HOW * ADD * AMOUNT OF * ARBITRARY INFORMATION *</pattern>
		<template>By reifying events.</template>
	</category>
	<category>
		<pattern>* HOW * ADD * AMOUNT OF * ARBITRARY INFORMATION *</pattern>
		<template>By reifying events.</template>
	</category>
	<category>
		<pattern>* WHY * EXTEND * EVENT CALCULUS *</pattern>
		<template>To make it possible to represent simultaneous events (such as two people being necessary to ride a seesaw), exogenous events (such as the wind blowing and changing the location of an object), continuous events (such as the level of water in the bathtub continuously rising) and other complications.</template>
	</category>
	<category>
		<pattern>* WHAT * EXTENDED EVENT CALCULUS * REPRESENT *</pattern>
		<template>It represents simultaneous events (such as two people being necessary to ride a seesaw), exogenous events (such as the wind blowing and changing the location of an object), continuous events (such as the level of water in the bathtub continuously rising) and other complications.</template>
	</category>
	<category>
		<pattern>* WHAT * PROCESS CATEGORIES *</pattern>
		<template>Categories of events with subinterval property.</template>
	</category>
	<category>
		<pattern>* WHAT * LIQUID EVENT CATEGORIES *</pattern>
		<template>Categories of events with subinterval property.</template>
	</category>
	<category>
		<pattern>* WHAT * CATEGORIES OF EVENTS * SUBINTERVAL PROPERTY * CALLED *</pattern>
		<template>Categories of events with this property are called process categories or liquid event categories.</template>
	</category>
	<category>
		<pattern>* WHAT * DISTINCTION * LIQUID * NONLIQUID *</pattern>
		<template>The distinction between liquid and nonliquid events is exactly analogous to the difference between substances, or stuff, and individual objects, or things.</template>
	</category>
	<category>
		<pattern>* WHAT * LIQUID EVENTS * CALLED *</pattern>
		<template>Some have called liquid events temporal substances.</template>
	</category>
	<category>
		<pattern>* WHAT * PHYSICAL OBJECTS *</pattern>
		<template>Physical objects can be viewed as generalized events, in the sense that a physical object is a chunk of space-time.</template>
	</category>
	<category>
		<pattern>* GIVE * ACTIONS * SITUATION CALCULUS * DESCRIBE *</pattern>
		<template>Actions are discrete, instantaneous, and happen one at a time.</template>
	</category>
	<category>
		<pattern>* GIVE * SITUATION CALCULUS * SAY *</pattern>
		<template>Situation calculus can say that the tub is empty before the action and Full when the action is done.</template>
	</category>
	<category>
		<pattern>* GIVE * SITUATION CALCULUS * CAN'T * DESCRIBE *</pattern>
		<template>It also can't describe two actions happening at the same time.</template>
	</category>
	<category>
		<pattern>* GIVE * SITUATION CALCULUS * CAN * NOT * DESCRIBE *</pattern>
		<template>It also can't describe two actions happening at the same time.</template>
	</category>
	<category>
		<pattern>* GIVE * SITUATION CALCULUS * CAN'T * DESCRIBE * TWO ACTIONS * HAPPENING * SAME TIME *</pattern>
		<template>Such as brushing one's teeth while waiting for the tub to fill.</template>
	</category>
	<category>
		<pattern>* GIVE * SITUATION CALCULUS * CAN * NOT * DESCRIBE * TWO ACTIONS * HAPPENING * SAME TIME *</pattern>
		<template>Such as brushing one's teeth while waiting for the tub to fill.</template>
	</category>
	<category>
		<pattern>* GIVE * EVENT CALCULUS * REIFY *</pattern>
		<template>Event calculus reifies fluents and events.</template>
	</category>
	<category>
		<pattern>* HOW * THE TERMS * EVENT * ACTION * MAY * USED *</pattern>
		<template>The terms "event" and "action" may be used interchangeably.</template>
	</category>
	<category>
		<pattern>* WHICH * ACTION * CONNOTES *</pattern>
		<template>Action connotes an agent.</template>
	</category>
	<category>
		<pattern>* WHICH * EVENT * CONNOTES *</pattern>
		<template>Event connotes the possibility of agentless actions.</template>
	</category>
	<category>
		<pattern>* WHAT * ACTION * CONNOTES *</pattern>
		<template>Action connotes an agent.</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT * CONNOTES *</pattern>
		<template>Event connotes the possibility of agentless actions.</template>
	</category>
	<category>
		<pattern>* GIVE * FLUENTS * ACTIONS * DEFINED * DOMAIN-SPECIFIC AXIOMS * SIMILAR * SUCCESSORSTATE AXIOMS *</pattern>
		<template>For example, we can say that the only way a wumpus-world agent gets an arrow is at the start, and the only way to use up an arrow is to shoot it.</template>
	</category>
	<category>
		<pattern>* GIVE * REIFYING * EVENTS * ADD * AMOUNT * ARBITRARY * INFORMATION *</pattern>
		<template>For example, we can say that Atta's flight was bumpy with Bumpy(E1).
 In an ontology where events are n-ary predicates, there would be no way to add extra information like this; moving to an n+ 1-ary predicate isn't a scalable solution.</template>
	</category>
	<category>
		<pattern>* GIVE * SIMULTANEOUS * EVENTS *</pattern>
		<template>Two people being necessary to ride a seesaw.</template>
	</category>
	<category>
		<pattern>* GIVE * EXOGENOUS * EVENTS *</pattern>
		<template>The wind blowing and changing the location of an object.</template>
	</category>
	<category>
		<pattern>* GIVE * CONTINUOUS * EVENTS *</pattern>
		<template>The level of water in the bathtub continuously rising.</template>
	</category>
	<category>
		<pattern>* GIVE * PROCESS * SUBINTERVAL *</pattern>
		<template>Any process e that happens over an interval also happens over any subinterval.</template>
	</category>
	<category>
		<pattern>* EVENT CALCULUS * OPEN * UP * TALKING * ABOUT *</pattern>
		<template>Event calculus opens us up to the possibility of talking about time, and time intervals.</template>
	</category>
	<category>
		<pattern>* GIVE * PHYSICAL OBJECTS * VIEWED * GENERALIZED EVENTS SENSE * A CHUNK * SPACE-TIME *</pattern>
		<template>For example, USA can be thought of as an event that began in, say, 1776 as a union of 13 states and is still in progress today as a union of 50.
 We can describe the changing properties of USA using state fluents, such as Population(USA).
 A property of the USA that changes every four or eight years, barring mishaps, is its president.One might propose that President(USA) is a logical term that denotes a different object at different times.</template>
	</category>
	<category>
		<pattern>* WHAT * AGENTS * ONLY * BELIEFS *</pattern>
		<template>they can deduce new knowledge.</template>
	</category>
	<category>
		<pattern>* HOW * KNOWLEDGE * ABOUT * KNOWLEDGE * USEFUL *</pattern>
		<template>it will be useful in reasoning process and used to control inference.</template>
	</category>
	<category>
		<pattern>* HOW * CONTROL * INFERENCE *</pattern>
		<template>knowledge about one's knowledge is useful for controlling inference.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * KNOWLEDGE * ABOUT * KNOWLEDGE * USEFUL *</pattern>
		<template>suppose ahmed asks ali "what is the square root of 1764" and ali replies "I don't know." If ahmed insists "think harder," ali should realize that with some more thought, this question can in fact be answered.
 On the other hand, if the question were "Is your mother sitting down right now" then ali should realize that thinking harder is unlikely to help</template>
	</category>
	<category>
		<pattern>* KNOWLEDGE * OTHER * KNOWLEDGE * USEFUL *</pattern>
		<template>one agent would know if the other agent knows something about himself or not and then asking him would be a convenient way to find out or not ; for example i don't know if my friend is sitting down now or not but i know that he knows that thing about himself then i would ask him.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * IMPORTANCE * KNOWLEDGE * ABOUT * KNOWLEDGE *</pattern>
		<template>suppose ahmed asks ali "what is the square root of 1764" and ali replies "I don't know." If ahmed insists "think harder," ali should realize that with some more thought, this question can in fact be answered.
 On the other hand, if the question were "Is your mother sitting down right now" then ali should realize that thinking harder is unlikely to help .
 the importance appears here ali should realize that his mother knows whether she is sitting or not, and that asking her would be a way to find out</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODEL * DETAILED *</pattern>
		<template>The model does not have to be detailed.
 We do not have to be able to predict how many milliseconds it will take for a particular agent to make a deduction.
 We will be happy just to be able to conclude that mother knows whether or not she is sitting</template>
	</category>
	<category>
		<pattern>* EXAMPLE * PROPOSITIONAL * ATTITUDES *</pattern>
		<template>they are attitudes an agent can have toward mental objects, attitudes such as Believes, Knows, Wants, Intends, and Informs</template>
	</category>
	<category>
		<pattern>* WHAT * PROPOSITIONAL * ATTITUDES *</pattern>
		<template>they are attitudes an agent can have toward mental objects, attitudes such as Believes, Knows, Wants, Intends, and Informs</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFICULT * PROPOSITIONAL * ATTITUDES *</pattern>
		<template>The difficulty is that these attitudes do not behave like "normal" predicates</template>
	</category>
	<category>
		<pattern>* EXAMPLE * PROPOSITIONAL * ATTITUDES * BEHAVE * PREDICATES *</pattern>
		<template>suppose we try to assert that Lois knows that Superman can fly: Knows(Lois, CanFly(Superman)) .
 One minor issue with this is that we normally think of CanFly(Superman) as a sentence, but here it appears as a term.
 That issue can be patched up just be reifying CanFly(Superman); making it a fluent.
 A more serious problem is that, if it is true that Superman is Clark Kent, Superman = Clark) AND Knows(Lois, CanFly(Superman)) |= Knows(Lois, CanFly(Clark)) .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * CONSEQUENCES * FACT * EQUALITY REASONING * BUILT * logic *</pattern>
		<template>if our agent knows that 2 + 2 = 4 and 4 less than 5, then we want our agent to know that 2 + 2 is less than 5</template>
	</category>
	<category>
		<pattern>* WHAT * TRANSPARENCY *</pattern>
		<template>it is property of logic that says , it doesn't matter what term a logic uses to refer to an object, what matters is the object that the term names.</template>
	</category>
	<category>
		<pattern>* WHAT * OPACITY *</pattern>
		<template>it is property of logic that says ,the term a logic uses to refer to an object do matter</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENCE BETWEEN * TRANSPARENCY * OPACITY *</pattern>
		<template>referential transparency: it doesn't matter what term a logic uses to refer to an object, what matters is the object that the term names.
 referential opacity : the terms used do matter, because not all agents know which terms are co-referentiaL.</template>
	</category>
	<category>
		<pattern>* WHAT * BETTER * USE * CONSIDERING * ATTITUDES * OPACITY * TRANSPARENCY *</pattern>
		<template>referential opacity</template>
	</category>
	<category>
		<pattern>* WHY * MODAL * DESIGNED *</pattern>
		<template>to address the problem of referential opacity and referential transparency</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENCE * MODAL * REGULAR *</pattern>
		<template>Regular logic is concerned with a single modality, the modality of truth, allowing us to express "P is true." Modal logic includes special modal operators that take sentences (rather than terms) as arguments.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODAL *</pattern>
		<template>"A knows P" is represented with the notation KAP, where K is the modal operator for knowledge.
 It takes two arguments, an agent (written as the subscript) and a sentence.
 The syntax of modal logic is the same as first-order logic, except that sentences can also be formed with modal operators1</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENCE * MODAL * FIRST ORDER *</pattern>
		<template>The syntax of modal logic is the same as first-order logic, except that sentences can also be formed with modal operators.</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFICULT * MODAL *</pattern>
		<template>The semantics of modal logic is more complicated</template>
	</category>
	<category>
		<pattern>* WHAT * MODEL * FIRST ORDER * CONTAIN *</pattern>
		<template>In first-order logic a model contains a set of objects and an interpretation that maps each name to the appropriate object, relation, or function.</template>
	</category>
	<category>
		<pattern>* WHY * NEED * COMPLEX MODEL * MODAL * FIRST ORDER *</pattern>
		<template>In modal logic we want to be able to consider both the possibility that some agent identity is Clark and that it isn't.
 Therefore, we will need a more complicated model</template>
	</category>
	<category>
		<pattern>* WHAT * COMPLEX MODEL * CONSIST OF *</pattern>
		<template>it consists of a collection of possible worlds rather than just one true world.
 The worlds are connected in a graph by accessibility relations, one relation for each modal operator.</template>
	</category>
	<category>
		<pattern>* WHAT * ACCESSIBILITY RELATIONS *</pattern>
		<template>given a graph that consists of a collection of possible worlds for an agent , The worlds are connected in a graph by accessibility relations, one relation for each modal operator.
 We say that world w1 is accessible from world w0 with respect to the modal operator K subscribt(A) if everything in w1 is consistent with what A knows in w0</template>
	</category>
	<category>
		<pattern>* WHEN K SUBSCRIPT(A) P * TRUE * WORLD * W *</pattern>
		<template>if P is true in every world accessible from w.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * WORLDS * ACCESSIBILITY RELATION *</pattern>
		<template>in the real world, Bucharest is the capital of Romania, but for an agent that did not know that, other possible worlds are accessible, including ones where the capital of Romania is Sibiu or Sofia</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODAL * REASON * NESTED *</pattern>
		<template>For example, we can say that, even though Lois doesn't know whether Superman's secret identity is Clark Kent, she does know that Clark knows: KLois[KClark Identity(Superman, Clark) OR KClark NOT (Identity(Superman, Clark))]</template>
	</category>
	<category>
		<pattern>* HOW * PROVE * TRUTH * COMPLEX *</pattern>
		<template>The truth of more complex sentences is derived by recursive application of the rule that says "if P is true in every world accessible from w." and the normal rules of first-order logic</template>
	</category>
	<category>
		<pattern>* MODAL * REASON * NESTED *</pattern>
		<template>Yes.</template>
	</category>
	<category>
		<pattern>* WHAT * NUMBER * WORLDS *</pattern>
		<template>infinity.</template>
	</category>
	<category>
		<pattern>* HOW * OVERCOME * INFINITY * WORLDS *</pattern>
		<template>introduce just the ones you need to represent what you are trying to model.</template>
	</category>
	<category>
		<pattern>* WHEN * NEED * ADD * WORLD *</pattern>
		<template>if it talks about different possible facts , or to talk about different states of knowledge</template>
	</category>
	<category>
		<pattern>* EXAMPLE * NEED * NEW * WORLD *</pattern>
		<template>A new possible world is needed to talk about different possible facts (e.g., rain is predicted or not), or to talk about different states of knowledge (e.g., does Lois know that rain is predicted)</template>
	</category>
	<category>
		<pattern>* CAN * TWO * WORLDS * SAME * BASE FACTS *</pattern>
		<template>yes , but differ in their accessibility relations, and therefore in facts about knowledge.</template>
	</category>
	<category>
		<pattern>* HOW * MODAL * DEAL * AMBIGIOUS * ENGLISH *</pattern>
		<template>Modal logic solves some tricky issues with the interplay of quantifiers and knowledge</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODAL * SOLVE * TRICKY * ISSUES *</pattern>
		<template>The English sentence "Bond knows that someone is a spy" is ambiguous.
 The first reading is that there is a particular someone who Bond knows is a spy; we can write this as (there exist ) x K subscript(Bond) Spy(x) , which in modal logic means that there is an x that, in all accessible worlds, Bond knows to be a spy.
 The second reading is that Bond just knows that there is at least one spy: K subscript(Bond) (there exist) x Spy(x) .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * AXIOMS * MODAL * OPERATOR * KNOWLEDGE *</pattern>
		<template>First, we can say that agents are able to draw deductions; if an agent knows P and knows that P implies Q, then the agent knows Q: (KaP AND Ka(P IMPLY Q)) IMPLY KaQ .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * TAUTOLOGY *</pattern>
		<template>First, we can say that agents are able to draw deductions; if an agent knows P and knows that P implies Q, then the agent knows Q: (KaP AND Ka(P IMPLY Q)) IMPLY KaQ .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * AXIOMS * MODAL * OPERATOR * KNOWLEDGE *</pattern>
		<template>from this rule (KaP and Ka(P imply Q)) imply KaQ (and a few other rules about logical identities) we can establish that KA(P or not(P)) is a tautology</template>
	</category>
	<category>
		<pattern>* IS (K SUBSCRIPT(A) P) OR (K SUBSCRIPT(A) NOT P) * tautology *</pattern>
		<template>NO</template>
	</category>
	<category>
		<pattern>* EXAMPLE * AXIOM *</pattern>
		<template>if you know something, it must be true, and we have the axiom: K SUBSCRIPT(a)P IMPLY P .</template>
	</category>
	<category>
		<pattern>* WHAT * OMNISCIENCE *</pattern>
		<template>if an agent knows a set of axioms, then it knows all consequences of those axioms</template>
	</category>
	<category>
		<pattern>* WHY * OMNISCIENCE * WORSE * Beliefs *</pattern>
		<template>because belief has more connotation of referring to things that are physically represented in the agent, not just potentially derivable</template>
	</category>
	<category>
		<pattern>* WHAT LOGICAL * SHOULD * INTROSPECT *</pattern>
		<template>logical agents should be able to introspect on their own knowledge.
 If they know something, then they know that they know it</template>
	</category>
	<category>
		<pattern>* INTROSPECT *</pattern>
		<template>logical agents should be able to introspect on their own knowledge.
 If they know something, then they know that they know it</template>
	</category>
	<category>
		<pattern>* WHAT * PROBLEMS * MODAL * APPROACH *</pattern>
		<template>one problem with the modal logic approach is that it assumes logical omniscience on the part of agents.
 That is, if an agent knows a set of axioms, then it knows all consequences of those axioms.
 This is on shaky ground even for the somewhat abstract notion of knowledge, but it seems even worse for belief, because belief has more connotation of referring to things that are physically represented in the agent, not just potentially derivable.</template>
	</category>
	<category>
		<pattern>* WHAT UPPER ONTOLOGY *</pattern>
		<template>The general framework of concepts.</template>
	</category>
	<category>
		<pattern>* WHAT * UPPER ONTOLOGY *</pattern>
		<template>The general framework of concepts.</template>
	</category>
	<category>
		<pattern>* WHAT * UPPER ONTOLOGY *</pattern>
		<template>The general framework of concepts.</template>
	</category>
	<category>
		<pattern>* WHAT * ONTOLOGICAL ENGINEERING *</pattern>
		<template>Representing abstract concepts such as Events, Time, Physical Objects, and Beliefs that occur in many different domains.</template>
	</category>
	<category>
		<pattern>* HOW * INTRODUCE * CLASSES * . *</pattern>
		<template>by describing the technology (TTL, CMOS, and so on) as well as the input-output specification.
 If we wanted to discuss reliability or diagnosis, we would include the possibility that the structure of the circuit or the properties of the gates might change spontaneously.
 To account for stray capacitances, we would need to represent where the wires are on the board.</template>
	</category>
	<category>
		<pattern>* GENERAL-PURPOSE ONTOLOGY * DIFFER * SPECIAL-PURPOSE ONTOLOGIES *</pattern>
		<template>A general-purpose ontology should be applicable in more or less any special-purpose domain (with the addition of domain-specific axioms).
 This means that no representational issue can be finessed or brushed under the carpet.
 In any sufficiently demanding domain, different areas of knowledge must be unified, because reasoning and problem solving could involve several areas simultaneously.
 A robot circuit-repair system, for instance, needs to reason about circuits in terms of electrical connectivity and physical layout, and about time, both for circuit timing analysis and estimating labor costs.
 The sentences describing time therefore must be capable of being combined with those describing spatial layout and must work equally well for nanoseconds and minutes and for angstroms and meters.</template>
	</category>
	<category>
		<pattern>* ROUTES * BUILD * EXISTING ONTOLOGIES *</pattern>
		<template>1.
 By a team of trained ontologist/logicians, who architect the ontology and write axioms.
 The CYC system was mostly built this way (Lenat and Guha, 1990).
 2.
 By importing categories, attributes, and values from an existing database or databases.
 DBPEDIA was built by importing structured facts from Wikipedia (Bizer et al., 2007).
 3.
 By parsing text documents and extracting information from them.
 TEXTRUNNER was built by reading a large corpus of Web pages (Banko and Etzioni, 2008).
 4.
 By enticing unskilled amateurs to enter commonsense knowledge.
 The OPENMIND system was built by volunteers who proposed facts in English (Singh et al., 2002; Chklovski and Gil, 2005).</template>
	</category>
	<category>
		<pattern>* WHAT * DEFINITION * REIFICATION *</pattern>
		<template>Turning a proposition into an object is called reification.</template>
	</category>
	<category>
		<pattern>* CATEGORIES * EXAMPLES *</pattern>
		<template>An object is a member of a category.
 BB9 belong to Basketballs.
 A category is a subclass of another category.
 Basketballs part of Balls.
 All members of a category have some properties.
 (xE Basketballs) -> Spherical(x).
 Members of a category can be recognized by some properties.
 Orange(x) xor Round(x) xor Diameter(x) = 9.5 xor xE Balls -> xE Basketballs.
 A category as a whole has some properties.
 Dogs part of DomesticatedSpecies</template>
	</category>
	<category>
		<pattern>* WHAT * DISJOINT CATEGORIES *</pattern>
		<template>two or more categories are disjoint if they have no members in common.</template>
	</category>
	<category>
		<pattern>* CHARACTERISTIC * CATEGORIES * COMPOSITE OBJECTS *</pattern>
		<template>Categories of composite objects are often characterized by structural relations among parts.</template>
	</category>
	<category>
		<pattern>* WHAT * LOGICAL MINIMIZATION *</pattern>
		<template>logical minimization means defining an object as the smallest one satisfying certain conditions.</template>
	</category>
	<category>
		<pattern>* WHEN * OBJECT * TRIANGLE *</pattern>
		<template>an object is a triangle if and only if it is a polygon with three sides.</template>
	</category>
	<category>
		<pattern>* WHAT * NATURAL KIND CATEGORIES *</pattern>
		<template>categories in the real world which have no clear-cut definition.</template>
	</category>
	<category>
		<pattern>* WHAT * MEASURES *</pattern>
		<template>The values that we assign for properties like e height, mass, cost, and so on.</template>
	</category>
	<category>
		<pattern>* WHAT * ASPECT * MEASURES *</pattern>
		<template>The most important aspect of measures is not the particular numerical values, but the fact that measures can be ordered.</template>
	</category>
	<category>
		<pattern>* WHAT * QUALITATIVE PHYSICS *</pattern>
		<template>a subfield of AI that investigates how to reason about physical systems without plunging into detailed equations and numerical simulations.</template>
	</category>
	<category>
		<pattern>* WHAT * INDIVIDUATION *</pattern>
		<template>division into distinct objects.</template>
	</category>
	<category>
		<pattern>* HOW * STUFF *</pattern>
		<template>begin with the obvious.
 We need to have as objects in our ontology at least the gross "lumps" of stuff we interact with.</template>
	</category>
	<category>
		<pattern>* WHAT * INTRINSIC PROPERTIES *</pattern>
		<template>they belong to the very substance of the object, rather than to the object as a whole.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * EXTRINSIC PROPERTIES *</pattern>
		<template>weight, length, shape, and so on.</template>
	</category>
	<category>
		<pattern>* WHY * SITUATION CALCULUS * LIMITE *</pattern>
		<template>it was designed to describe a world in which actions are discrete, instantaneous, and happen one at a time.
 Consider a continuous action, such as filling a bathtub.
 Situation calculus can say that the tub is empty before the action and full when the action is done, but it can't talk about what happens during the action.
 It also can't describe two actions happening at the same time.</template>
	</category>
	<category>
		<pattern>* WHAT * ACTION * CONNOTE *</pattern>
		<template>action connotes an agent</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT * CONNOTE *</pattern>
		<template>event connotes the possibility of agentless actions</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT CALCULUS *</pattern>
		<template>an alternative formalism to situation calculus known as event calculus, which is based on points of time rather than on situations</template>
	</category>
	<category>
		<pattern>* WHAT * DISCRETE EVENTS *</pattern>
		<template>they have a definite structure.</template>
	</category>
	<category>
		<pattern>* WHAT * PROPOSITIONAL ATTITUDES *</pattern>
		<template>attitudes that an agent can have toward mental objects, attitudes such as Believes, Knows, Wants, Intends, and Informs.
 The difficulty is that these attitudes do not behave like "normal" predicates.</template>
	</category>
	<category>
		<pattern>* WHAT * REFERENTIAL TRANSPARENCY *</pattern>
		<template>it doesn't matter what REFERENTIAL TRANSPARENCY term a logic uses to refer to an object, what matters is the object that the term names.</template>
	</category>
	<category>
		<pattern>* WHAT * AGENTS * ONLY * BELIEFS *</pattern>
		<template>they can deduce new knowledge.</template>
	</category>
	<category>
		<pattern>* HOW * KNOWLEDGE * ABOUT * KNOWLEDGE * USEFUL *</pattern>
		<template>it will be useful in reasoning process and used to control inference.</template>
	</category>
	<category>
		<pattern>* HOW * CONTROL * INFERENCE *</pattern>
		<template>knowledge about one's knowledge is useful for controlling inference.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * KNOWLEDGE * ABOUT * KNOWLEDGE * USEFUL *</pattern>
		<template>suppose ahmed asks ali "what is the square root of 1764" and ali replies "I don't know." If ahmed insists "think harder," ali should realize that with some more thought, this question can in fact be answered.
 On the other hand, if the question were "Is your mother sitting down right now" then ali should realize that thinking harder is unlikely to help</template>
	</category>
	<category>
		<pattern>* KNOWLEDGE * OTHER * KNOWLEDGE * USEFUL *</pattern>
		<template>one agent would know if the other agent knows something about himself or not and then asking him would be a convenient way to find out or not ; for example i don't know if my friend is sitting down now or not but i know that he knows that thing about himself then i would ask him.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * IMPORTANCE * KNOWLEDGE * ABOUT * KNOWLEDGE *</pattern>
		<template>suppose ahmed asks ali "what is the square root of 1764" and ali replies "I don't know." If ahmed insists "think harder," ali should realize that with some more thought, this question can in fact be answered.
 On the other hand, if the question were "Is your mother sitting down right now" then ali should realize that thinking harder is unlikely to help .
 the importance appears here ali should realize that his mother knows whether she is sitting or not, and that asking her would be a way to find out</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODEL * DETAILED *</pattern>
		<template>The model does not have to be detailed.
 We do not have to be able to predict how many milliseconds it will take for a particular agent to make a deduction.
 We will be happy just to be able to conclude that mother knows whether or not she is sitting</template>
	</category>
	<category>
		<pattern>* EXAMPLE * PROPOSITIONAL * ATTITUDES *</pattern>
		<template>they are attitudes an agent can have toward mental objects, attitudes such as Believes, Knows, Wants, Intends, and Informs</template>
	</category>
	<category>
		<pattern>* WHAT * PROPOSITIONAL * ATTITUDES *</pattern>
		<template>they are attitudes an agent can have toward mental objects, attitudes such as Believes, Knows, Wants, Intends, and Informs</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFICULT * PROPOSITIONAL * ATTITUDES *</pattern>
		<template>The difficulty is that these attitudes do not behave like "normal" predicates</template>
	</category>
	<category>
		<pattern>* EXAMPLE * PROPOSITIONAL * ATTITUDES * BEHAVE * PREDICATES *</pattern>
		<template>suppose we try to assert that Lois knows that Superman can fly: Knows(Lois, CanFly(Superman)) .
 One minor issue with this is that we normally think of CanFly(Superman) as a sentence, but here it appears as a term.
 That issue can be patched up just be reifying CanFly(Superman); making it a fluent.
 A more serious problem is that, if it is true that Superman is Clark Kent, Superman = Clark) AND Knows(Lois, CanFly(Superman)) |= Knows(Lois, CanFly(Clark)) .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * CONSEQUENCES * FACT * EQUALITY REASONING * BUILT * logic *</pattern>
		<template>if our agent knows that 2 + 2 = 4 and 4 less than 5, then we want our agent to know that 2 + 2 is less than 5</template>
	</category>
	<category>
		<pattern>* WHAT * TRANSPARENCY *</pattern>
		<template>it is property of logic that says , it doesn't matter what term a logic uses to refer to an object, what matters is the object that the term names.</template>
	</category>
	<category>
		<pattern>* WHAT * OPACITY *</pattern>
		<template>it is property of logic that says ,the term a logic uses to refer to an object do matter</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENCE BETWEEN * TRANSPARENCY * OPACITY *</pattern>
		<template>referential transparency: it doesn't matter what term a logic uses to refer to an object, what matters is the object that the term names.
 referential opacity : the terms used do matter, because not all agents know which terms are co-referentiaL.</template>
	</category>
	<category>
		<pattern>* WHAT * BETTER * USE * CONSIDERING * ATTITUDES * OPACITY * TRANSPARENCY *</pattern>
		<template>referential opacity</template>
	</category>
	<category>
		<pattern>* WHY * MODAL * DESIGNED *</pattern>
		<template>to address the problem of referential opacity and referential transparency</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENCE * MODAL * REGULAR *</pattern>
		<template>Regular logic is concerned with a single modality, the modality of truth, allowing us to express "P is true." Modal logic includes special modal operators that take sentences (rather than terms) as arguments.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODAL *</pattern>
		<template>"A knows P" is represented with the notation KAP, where K is the modal operator for knowledge.
 It takes two arguments, an agent (written as the subscript) and a sentence.
 The syntax of modal logic is the same as first-order logic, except that sentences can also be formed with modal operators1</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENCE * MODAL * FIRST ORDER *</pattern>
		<template>The syntax of modal logic is the same as first-order logic, except that sentences can also be formed with modal operators.</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFICULT * MODAL *</pattern>
		<template>The semantics of modal logic is more complicated</template>
	</category>
	<category>
		<pattern>* WHAT * MODEL * FIRST ORDER * CONTAIN *</pattern>
		<template>In first-order logic a model contains a set of objects and an interpretation that maps each name to the appropriate object, relation, or function.</template>
	</category>
	<category>
		<pattern>* WHY * NEED * COMPLEX MODEL * MODAL * FIRST ORDER *</pattern>
		<template>In modal logic we want to be able to consider both the possibility that some agent identity is Clark and that it isn't.
 Therefore, we will need a more complicated model</template>
	</category>
	<category>
		<pattern>* WHAT * COMPLEX MODEL * CONSIST OF *</pattern>
		<template>it consists of a collection of possible worlds rather than just one true world.
 The worlds are connected in a graph by accessibility relations, one relation for each modal operator.</template>
	</category>
	<category>
		<pattern>* WHAT * ACCESSIBILITY RELATIONS *</pattern>
		<template>given a graph that consists of a collection of possible worlds for an agent , The worlds are connected in a graph by accessibility relations, one relation for each modal operator.
 We say that world w1 is accessible from world w0 with respect to the modal operator K subscribt(A) if everything in w1 is consistent with what A knows in w0</template>
	</category>
	<category>
		<pattern>* WHEN K SUBSCRIPT(A) P * TRUE * WORLD * W *</pattern>
		<template>if P is true in every world accessible from w.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * WORLDS * ACCESSIBILITY RELATION *</pattern>
		<template>in the real world, Bucharest is the capital of Romania, but for an agent that did not know that, other possible worlds are accessible, including ones where the capital of Romania is Sibiu or Sofia</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODAL * REASON * NESTED *</pattern>
		<template>For example, we can say that, even though Lois doesn't know whether Superman's secret identity is Clark Kent, she does know that Clark knows: KLois[KClark Identity(Superman, Clark) OR KClark NOT (Identity(Superman, Clark))]</template>
	</category>
	<category>
		<pattern>* HOW * PROVE * TRUTH * COMPLEX *</pattern>
		<template>The truth of more complex sentences is derived by recursive application of the rule that says "if P is true in every world accessible from w." and the normal rules of first-order logic</template>
	</category>
	<category>
		<pattern>* MODAL * REASON * NESTED *</pattern>
		<template>Yes.</template>
	</category>
	<category>
		<pattern>* WHAT * NUMBER * WORLDS *</pattern>
		<template>infinity.</template>
	</category>
	<category>
		<pattern>* HOW * OVERCOME * INFINITY * WORLDS *</pattern>
		<template>introduce just the ones you need to represent what you are trying to model.</template>
	</category>
	<category>
		<pattern>* WHEN * NEED * ADD * WORLD *</pattern>
		<template>if it talks about different possible facts , or to talk about different states of knowledge</template>
	</category>
	<category>
		<pattern>* EXAMPLE * NEED * NEW * WORLD *</pattern>
		<template>A new possible world is needed to talk about different possible facts (e.g., rain is predicted or not), or to talk about different states of knowledge (e.g., does Lois know that rain is predicted)</template>
	</category>
	<category>
		<pattern>* CAN * TWO * WORLDS * SAME * BASE FACTS *</pattern>
		<template>yes , but differ in their accessibility relations, and therefore in facts about knowledge.</template>
	</category>
	<category>
		<pattern>* HOW * MODAL * DEAL * AMBIGIOUS * ENGLISH *</pattern>
		<template>Modal logic solves some tricky issues with the interplay of quantifiers and knowledge</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MODAL * SOLVE * TRICKY * ISSUES *</pattern>
		<template>The English sentence "Bond knows that someone is a spy" is ambiguous.
 The first reading is that there is a particular someone who Bond knows is a spy; we can write this as (there exist ) x K subscript(Bond) Spy(x) , which in modal logic means that there is an x that, in all accessible worlds, Bond knows to be a spy.
 The second reading is that Bond just knows that there is at least one spy: K subscript(Bond) (there exist) x Spy(x) .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * AXIOMS * MODAL * OPERATOR * KNOWLEDGE *</pattern>
		<template>First, we can say that agents are able to draw deductions; if an agent knows P and knows that P implies Q, then the agent knows Q: (KaP AND Ka(P IMPLY Q)) IMPLY KaQ .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * TAUTOLOGY *</pattern>
		<template>First, we can say that agents are able to draw deductions; if an agent knows P and knows that P implies Q, then the agent knows Q: (KaP AND Ka(P IMPLY Q)) IMPLY KaQ .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * AXIOMS * MODAL * OPERATOR * KNOWLEDGE *</pattern>
		<template>from this rule (KaP and Ka(P imply Q)) imply KaQ (and a few other rules about logical identities) we can establish that KA(P or not(P)) is a tautology</template>
	</category>
	<category>
		<pattern>* IS (K SUBSCRIPT(A) P) OR (K SUBSCRIPT(A) NOT P) * tautology *</pattern>
		<template>NO</template>
	</category>
	<category>
		<pattern>* EXAMPLE * AXIOM *</pattern>
		<template>if you know something, it must be true, and we have the axiom: K SUBSCRIPT(a)P IMPLY P .</template>
	</category>
	<category>
		<pattern>* WHAT * OMNISCIENCE *</pattern>
		<template>if an agent knows a set of axioms, then it knows all consequences of those axioms</template>
	</category>
	<category>
		<pattern>* WHY * OMNISCIENCE * WORSE * Beliefs *</pattern>
		<template>because belief has more connotation of referring to things that are physically represented in the agent, not just potentially derivable</template>
	</category>
	<category>
		<pattern>* WHAT LOGICAL * SHOULD * INTROSPECT *</pattern>
		<template>logical agents should be able to introspect on their own knowledge.
 If they know something, then they know that they know it</template>
	</category>
	<category>
		<pattern>* INTROSPECT *</pattern>
		<template>logical agents should be able to introspect on their own knowledge.
 If they know something, then they know that they know it</template>
	</category>
	<category>
		<pattern>* WHAT * PROBLEMS * MODAL * APPROACH *</pattern>
		<template>one problem with the modal logic approach is that it assumes logical omniscience on the part of agents.
 That is, if an agent knows a set of axioms, then it knows all consequences of those axioms.
 This is on shaky ground even for the somewhat abstract notion of knowledge, but it seems even worse for belief, because belief has more connotation of referring to things that are physically represented in the agent, not just potentially derivable.</template>
	</category>
	<category>
		<pattern>* WHAT * COMPOSITE OBJECT *</pattern>
		<template>Categories of composite objects are often characterized by structural relations among parts.
 For example, a biped has two legs attached to a body</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * PartPartition *</pattern>
		<template>The mass of a composite object is the sum of the masses of the parts.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * COMPOSITE OBJECTS * DEFINITE PARTS *</pattern>
		<template>we might want to say "The apples in this bag weigh two pounds." The temptation would be to ascribe this weight to the set of apples in the bag, but this would be a mistake because the set is an abstract mathematical concept that has elements but does not have weight.</template>
	</category>
	<category>
		<pattern>* PartPartition * relation analogous *</pattern>
		<template>To Partition relation for categories.
 An object is composed of the parts in its PartPartition and can be viewed as deriving some properties from those parts.
 It is also useful to define composite objects with definite parts but no particular structure.</template>
	</category>
	<category>
		<pattern>* WHAT * PartPartition *</pattern>
		<template>To Partition relation for categories.
 An object is composed of the parts in its PartPartition and can be viewed as deriving some properties from those parts.
 It is also useful to define composite objects with definite parts but no particular structure.</template>
	</category>
	<category>
		<pattern>* WHAT * BUNCH *</pattern>
		<template>Bunch is a collection of thing.
 For example, if the apples are Apple1, Apple2, and Apple3, then BunchOf ({Apple1,Apple2,Apple3})</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * BUNCH *</pattern>
		<template>If the apples are Apple1, Apple2, and Apple3, then BunchOf ({Apple1,Apple2,Apple3})</template>
	</category>
	<category>
		<pattern>* WHAT * LOGICAL MINIMIZATION *</pattern>
		<template>It means defining an object as the smallest one satisfying certain conditions.</template>
	</category>
	<category>
		<pattern>* WHAT * MEASURE *</pattern>
		<template>In both scientific and commonsense theories of the world, objects have height, mass, cost, and so on.
 The values that we assign for these MEASURE properties are called measures.</template>
	</category>
	<category>
		<pattern>* WHAT * MEASURES *</pattern>
		<template>In both scientific and commonsense theories of the world, objects have height, mass, cost, and so on.
 The values that we assign for these MEASURE properties are called measures.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * MEASURE OBJECTS *</pattern>
		<template>The length that is the length of this line segment</template>
	</category>
	<category>
		<pattern>* WHAT * UNITS FUNCTION *</pattern>
		<template>It is the function that takes a number as argument.
 we can write Length(L1)=Inches(1.5)=Centimeters(3.81)</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * UNITS FUNCTION *</pattern>
		<template>Length(L1)=Inches(1.5)=Centimeters(3.81)</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * CONVERSION * UNITS *</pattern>
		<template>Centimeters(2.54 x d) = Inches(d) .</template>
	</category>
	<category>
		<pattern>* WHY * MEASURES * PRESENT * PROBLEM *</pattern>
		<template>Simple, quantitative measures are easy to represent,But other measures present more of a problem, because t hey have no agreed scale of values.</template>
	</category>
	<category>
		<pattern>* WHAT * IMPORTANT * ASPECT * MEASURES *</pattern>
		<template>The most important aspect of measures is the fact that measures can be ordered</template>
	</category>
	<category>
		<pattern>* HOW * REAL WORLD * SEEN *</pattern>
		<template>The real world can be seen as consisting of primitive objects (e.g., atomic particles) and composite objects built from them.</template>
	</category>
	<category>
		<pattern>* HOW * OVERCOME * COMPLEXITY * INVOLVED * DEALING * PRIMITIVE OBJECTS *</pattern>
		<template>By reasoning at the level of large objects such as apples and cars, we can overcome the complexity involved in dealing with vast numbers of primitive objects individually.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * STUFF *</pattern>
		<template>For example, suppose I have some butter and an aardvark in front of me.
 I can say there is one aardvark, but there is no obvious number of "butter-objects," because any part of a butter-object is also a butter-object, at least until we get to very small parts indeed.
 This is the major distinction between stuff and things.
 If we cut an aardvark in half, we do not get two aardvarks</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENT * STUFF * THINGS *</pattern>
		<template>For example, suppose I have some butter and an aardvark in front of me.
 I can say there is one aardvark, but there is no obvious number of "butter-objects," because any part of a butter-object is also a butter-object, at least until we get to very small parts indeed.
 This is the major distinction between stuff and things.
 If we cut an aardvark in half, we do not get two aardvarks</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * COUNT NOUNS *</pattern>
		<template>aardvarks, holes, and theorems</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * MASS NOUN *</pattern>
		<template>butter, water, and energy</template>
	</category>
	<category>
		<pattern>* WHAT * COMPETING ONTOLOGIES * CLAIM *</pattern>
		<template>Several competing ontologies claim to handle this distinction.</template>
	</category>
	<category>
		<pattern>* WHAT * INTRINSIC *</pattern>
		<template>They belong to the very substance of the object, rather than to the object as a whole.
 When you cut an instance of stuff in half, the two pieces retain the intrinsic properties-things like density, boiling point, flavor, color, ownership, and so on.</template>
	</category>
	<category>
		<pattern>* WHAT * EXTRINSIC *</pattern>
		<template>The extrinsic properties such as weight, length, shape, and so on-are not retained under subdivision.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * INTRINSIC *</pattern>
		<template>density,boiling point, flavor, color, ownership, and so on.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * EXTRINSIC *</pattern>
		<template>weight, length, shape, and so on-are not retained under subdivision.</template>
	</category>
	<category>
		<pattern>* HOW * REAL * WORLD * SEEN *</pattern>
		<template>The real world can be seen as consisting of primitive objects , (e.g., atomic particles) and composite objects built from them</template>
	</category>
	<category>
		<pattern>* EXAMPLE * PRIMITIVE *</pattern>
		<template>Atomic particles</template>
	</category>
	<category>
		<pattern>* HOW * overcome * complexity * dealing * vast * primitive * individually *</pattern>
		<template>we can overcome the complexity involved in dealing with vast numbers of primitive objects individually</template>
	</category>
	<category>
		<pattern>* how * portion * reality * defy * individuation *</pattern>
		<template>We give this portion the generic name stuff</template>
	</category>
	<category>
		<pattern>* DIFFERENCE * STUFF * THINGS *</pattern>
		<template>Suppose we have some butter and an aardvark in front of us .
 we can say there is one aardvark, but there is no obvious number of "butter-objects," because any part of a butter-object is also a butter-object, at least until we get to very small parts indeed.
 This is the major distinction between stuff and things</template>
	</category>
	<category>
		<pattern>* EXAMPLE * STUFF * THINGS *</pattern>
		<template>aardvark is a thing but butter is a stuff</template>
	</category>
	<category>
		<pattern>* HOW * ENGLISH * DISTINGUISH * STUFF * THING *</pattern>
		<template>The English language distinguishes clearly between stuff and things.
 We say "an aardvark," but, except in pretentious California restaurants, one cannot say "a butter." Linguists distinguish between count nouns, such as aardvarks, holes, and theorems, and mass nouns,such as butter, water, and energy</template>
	</category>
	<category>
		<pattern>* HOW * REPRESENT * STUFF *</pattern>
		<template>We begin with the obvious.
 We need to have as objects in our ontology at least the gross "lumps" of stuff we interact with.
 For example, we might recognize a lump of butter as the one left on the table the night before; we might pick it up, weigh it, sell it, or whatever.
 In these senses, it is an object just like the aardvark.
 Let us call it Butter3.
 We also define the category Butter.
 Informally, its elements will be all those things of which one might say "It's butter," including Butter3.
 With some caveats about very small parts that we w omit for now, any part of a butter-object is also a butter-object: b (belongs to) Butter and PartOf(p, b) imply p (belongs to) Butter.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * STUFF * REPRESENTATION *</pattern>
		<template>For example, we might recognize a lump of butter as the one left on the table the night before; we might pick it up, weigh it, sell it, or whatever.
 In these senses, it is an object just like the aardvark.
 Let us call it Butter3.
 We also define the category Butter.
 Informally, its elements will be all those hings of which one might say "It's butter," including Butter3.
 With some caveats about very small parts that we w omit for now, any part of a butter-object is also a butter-object: b (belongs to) Butter and PartOf(p, b) imply p (belongs to) Butter.
 We can now say that butter melts at around 30 degrees centigrade: b E Butter -> MeltingPoint(b, Centigrade(30)) .</template>
	</category>
	<category>
		<pattern>* EXAMPLE * STUFF * REPRESENTATION *</pattern>
		<template>For example, we might recognize a lump of butter as the one left on the table the night before; we might pick it up, weigh it, sell it, or whatever.
 In these senses, it is an object just like the aardvark.
 Let us call it Butter3.
 We also define the category Butter.
 Informally, its elements will be all those hings of which one might say "It's butter," including Butter3.
 With some caveats about very small parts that we w omit for now, any part of a butter-object is also a butter-object: b (belongs to) Butter and PartOf(p, b) imply p (belongs to) Butter.
 for example We can now say that butter melts at around 30 degrees centigrade: b (belongs to ) Butter imply MeltingPoint(b, Centigrade(30)).</template>
	</category>
	<category>
		<pattern>* EXAMPLE * BUTTER * REPRESENTATION *</pattern>
		<template>We could say that butter is yellow,less dense than water, soft at room temperature, has a high fat content, and so on.
 On the other hand, butter has no particular size, shape,or weight.
 We can define more specialized categories of butter such as UnsaltedButter, which is also a kind of stuff.</template>
	</category>
	<category>
		<pattern>* CATEOGRY * TYPE * PROPERTIES *</pattern>
		<template>Intrinsic and extrinsic</template>
	</category>
	<category>
		<pattern>* WHAT * DIFFERENCE * INTRINSIC * EXTRINSIC *</pattern>
		<template>Intrinsic : constant even if stuff were split up into 2 parts like density , melting point Extrinsic : variable like shape and weight.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * INTRINSIC * EXTRINSIC *</pattern>
		<template>Intrinsic : density and melting point Extrinsic : shape and weight.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * INTRINSIC *</pattern>
		<template>Intrinsic : density and melting point</template>
	</category>
	<category>
		<pattern>* EXAMPLE * EXTRINSIC *</pattern>
		<template>Extrinsic : shape and weight.</template>
	</category>
	<category>
		<pattern>* WHAT * INTRINSIC *</pattern>
		<template>Some properties are intrinsic: they belong to the very substance of the object, rather than to the object as a whole.
 When you cut an instance of stuff in half, the two pieces retain the intrinsic properties-things like density, boiling point, flavor, color, ownership, and so on</template>
	</category>
	<category>
		<pattern>* WHAT * EXTRINSIC *</pattern>
		<template>Extrinsic properties like weight, length, shape, and so on are not retained under subdivision</template>
	</category>
	<category>
		<pattern>* CATEGORY * INCLUDES * INTRINSIC PROPERTIES *</pattern>
		<template>A category of objects that includes in its definition only intrinsic properties is then a substance, or mass noun</template>
	</category>
	<category>
		<pattern>* CATEGORY * INCLUDES * EXTRINSIC PROPERTIES *</pattern>
		<template>A class that includes any extrinsic properties in its definition is a count noun</template>
	</category>
	<category>
		<pattern>* CATEGORY * INCLUDES * EXTRINSIC PROPERTIES *</pattern>
		<template>A class that includes any extrinsic properties in its definition is a count noun</template>
	</category>
	<category>
		<pattern>* CATEGORY * INCLUDES * EXTRINSIC PROPERTIES *</pattern>
		<template>A class that includes any extrinsic properties in its definition is a count noun</template>
	</category>
	<category>
		<pattern>* REPRESENTING * ABSTRACT CONCEPTS *</pattern>
		<template>Representing these abstract concepts is called ontological thinking</template>
	</category>
	<category>
		<pattern>* CHAPTER 12 *</pattern>
		<template>It addresses the question of what content to put into such an agent's knowledge base-how to represent facts about the world.</template>
	</category>
	<category>
		<pattern>* SECTION 12.1 *</pattern>
		<template>It introduces the idea of a general ontology, which organizes everything in the world into a hierarchy of categories</template>
	</category>
	<category>
		<pattern>* SECTION 12.2 *</pattern>
		<template>It covers the basic categories of objects, substances and measures</template>
	</category>
	<category>
		<pattern>* SECTION 12.3 *</pattern>
		<template>It covers events</template>
	</category>
	<category>
		<pattern>* SECTION 12.4 *</pattern>
		<template>It discusses knowledge about beliefs</template>
	</category>
	<category>
		<pattern>* SECTION 12.5 *</pattern>
		<template>It discusses reasoning systems designed for efficient inference with categories</template>
	</category>
	<category>
		<pattern>* SECTION 12.6 *</pattern>
		<template>If discusses reasoning with default information</template>
	</category>
	<category>
		<pattern>* SECTION 12.7 *</pattern>
		<template>It brings all the knowledge together in the context of an Internet shopping environment</template>
	</category>
	<category>
		<pattern>* COMPLEX DOMAINS *</pattern>
		<template>It requires more general and flexible representations</template>
	</category>
	<category>
		<pattern>* ONTOLOGICAL ENGINEERING *</pattern>
		<template>Representing abstract concepts such as Events, Time, Physical Objects, and Beliefs that occur in many different domains.</template>
	</category>
	<category>
		<pattern>* REPRESENTING * EVERYTHING *</pattern>
		<template>It's very daunting Because we won't actually write a complete description of everything as that would be far too much for even a 1000-page textbook</template>
	</category>
	<category>
		<pattern>* INSTEAD * REPRESENTING * EVERYTHING *</pattern>
		<template>we will leave placeholders where new knowledge for any domain can fit in.
 For example, we will define what it means to be a physical object, and the details of different types of objects robots, televisions, books, or whatever can be filled in later.</template>
	</category>
	<category>
		<pattern>* Replacement * REPRESENTING * EVERYTHING *</pattern>
		<template>we will leave placeholders where new knowledge for any domain can fit in.
 For example, we will define what it means to be a physical object, and the details of different types of objects robots, televisions, books, or whatever can be filled in later.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * PLACEHOLDERS *</pattern>
		<template>the way that designers of an object-oriented programming framework (such as the Java Swing graphical framework) define general concepts like Window, expecting users to use these to define more specific concepts like SpreadsheetWindw.</template>
	</category>
	<category>
		<pattern>* UPPER ONTOLOGY *</pattern>
		<template>The general framework of concepts is called an upper ontology because of the convention of drawing graphs with the general concepts at the top and the more specific concepts below them</template>
	</category>
	<category>
		<pattern>* CALLED * UPPER ONTOLOGY *</pattern>
		<template>because of the convention of drawing graphs with the general concepts at the top and the more specific concepts below them</template>
	</category>
	<category>
		<pattern>* CONVENTION * UPPER ONTOLOGY *</pattern>
		<template>Drawing graphs with the general concepts at the top and the more specific concepts below them</template>
	</category>
	<category>
		<pattern>* FOL *</pattern>
		<template>First-order logic is a collection of formal systems used in mathematics, philosophy, linguistics, and computer science.
 It is also known as first-order predicate calculus, the lower predicate calculus, quantification theory, and predicate logic.
 First-order logic uses quantified variables over (non-logical) objects.
 This distinguishes it from propositional logic, which does not use quantifiers.</template>
	</category>
	<category>
		<pattern>* FIRST ORDER LOGIC *</pattern>
		<template>First-order logic is a collection of formal systems used in mathematics, philosophy, linguistics, and computer science.
 It is also known as first-order predicate calculus, the lower predicate calculus, quantification theory, and predicate logic.
 First-order logic uses quantified variables over (non-logical) objects.
 This distinguishes it from propositional logic, which does not use quantifiers.</template>
	</category>
	<category>
		<pattern>* ONTOLOGY *</pattern>
		<template>An ontology is a formal naming and definition of the types, properties, and interrelationships of the entities that really or fundamentally exist for a particular domain of discourse.
 It is thus a practical application of philosophical ontology, with a taxonomy.</template>
	</category>
	<category>
		<pattern>* ORGANIZATION OF KNOWLEDGE *</pattern>
		<template>We have elected first order logic</template>
	</category>
	<category>
		<pattern>* DIFFICULTY * FOL *</pattern>
		<template>Aspects of the real world are hard to capture in FOL, the principal difficulty is that most generalizations have exceptions or hold only to a degree.
 For example, although tomatoes are red is a useful rule, some tomatoes are green, yellow, or orange.</template>
	</category>
	<category>
		<pattern>* DIFFICULTY * FIRST ORDER LOGIC *</pattern>
		<template>The principal difficulty is that most generalizations have exceptions or hold only to a degree.
 For example, although tomatoes are red is a useful rule, some tomatoes are green, yellow, or orange.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * EXCEPTIONS * KNOWLEDGE *</pattern>
		<template>For example, although tomatoes are red is a useful rule, some tomatoes are green, yellow, or orange</template>
	</category>
	<category>
		<pattern>* EXAMPLE * UPPER ONTOLOGY *</pattern>
		<template>Consider an ontology for circuits It makes many simplifying assumptions: time is omitted completely; signals are fixed and do not propagate; the structure of the circuit remains constant.
 A more general ontology would consider signals at particular times, and would include the wire lengths and propagation delays.
 This would allow us to simulate the timing properties of the circuit, and indeed such simulations are often carried out by circuit designers.
 We could also introduce more interesting classes of gates, for example, by describing the technology (TTL, CMOS, and so on) as well as the input output specification.
 If we wanted to discuss reliability or diagnosis, we would include the possibility that the structure of the circuit or the properties of the gates might change spontaneously.
 To account for stray capacitances, we would need to represent where the wires are on the board.</template>
	</category>
	<category>
		<pattern>* TIME * THE WUMPUS WORLD *</pattern>
		<template>Although we do represent time, it has a simple structure: Nothing happens except when the agent acts, and all changes are instantaneous, but a more general ontology, better suited for the real world, would allow for simultaneous changes extended over time</template>
	</category>
	<category>
		<pattern>* WHICH SQUARES HAVE PITS * WUMPUS WORLD *</pattern>
		<template>We used a Pit predicate to say which squares have pits.</template>
	</category>
	<category>
		<pattern>* WHY * PIT PREDICATE * WUMPUS WORLD *</pattern>
		<template>to say which squares have pits</template>
	</category>
	<category>
		<pattern>* TIME * REAL WORLD * WUMPUS *</pattern>
		<template>we would allow for simultaneous changes extended over time</template>
	</category>
	<category>
		<pattern>* KINDS * OF * PITS * WUMPUS *</pattern>
		<template>by having several individuals belonging to the class of pits</template>
	</category>
	<category>
		<pattern>* ANIMALS * WUMPUS *</pattern>
		<template>It might not be possible to pin down the exact species from the available percepts, so we would need to build up a biological taxonomy to help the agent predict the behavior of cave-dwellers from scanty clues.</template>
	</category>
	<category>
		<pattern>* ONTOLOGIES * CONVERGE * GENERAL * PURPOSE * ONTOLOGY *</pattern>
		<template>After centuries of philosophical and computational investigation, the answer is "Maybe.</template>
	</category>
	<category>
		<pattern>* GENERAL * PURPOSE * ONTOLOGIES * SPECIAL * PURPOSE *</pattern>
		<template>There are Two major characteristics of general-purpose ontologies distinguish them from collections of special-purpose ontologies: 1- A general-purpose ontology should be applicable in more or less any special-purpose domain (with the addition of domain-specific axioms).
 This means that no representational issue can be finessed or brushed under the carpet.
 2- In any sufficiently demanding domain, different areas of knowledge must be unified, because reasoning and problem solving could involve several areas simultaneously.
 A robot circuit-repair system, for instance, needs to reason about circuits in terms of electrical connectivity and physical layout, and about time, both for circuit timing analysis and estimating labor costs.
 The sentences describing time therefore must be capable of being combined with those describing spatial layout and must work equally well for nanoseconds and minutes and for angstroms and meters.</template>
	</category>
	<category>
		<pattern>* WHY * DIFFERENT * KNOWLEDGE UNIFIED *</pattern>
		<template>because reasoning and problem solving could involve several areas simultaneously.
 A robot circuit-repair system, for instance, needs to reason about circuits in terms of electrical connectivity and physical layout, and about time, both for circuit timing analysis and estimating labor costs.
 The sentences describing time therefore must be capable of being combined with those describing spatial layout and must work equally well for nanoseconds and minutes and for angstroms and meters.</template>
	</category>
	<category>
		<pattern>* TOP AI APPLICATIONS * ONTOLOGY *</pattern>
		<template>they all use special-purpose knowledge engineering.
 Social/political considerations can make it difficult for competing parties to agree on an ontology.
 As Tom Gruber (2004) says, "Every ontology is a treaty-a social agreement-among people with some common motive in sharing." When competing concerns outweigh the motivation for sharing, there can be no common ontology</template>
	</category>
	<category>
		<pattern>* WHO * EVERY ONTOLOGY IS A TREATY *</pattern>
		<template>Tom Gruber (2004)</template>
	</category>
	<category>
		<pattern>* ONTOLOGIES * CREATE *</pattern>
		<template>Those ontologies that do exist have been created along four routes: 1.
 By a team of trained ontologist/logicians, who architect the ontology and write axioms.
 The CYC system was mostly built this way (Lenat and Guha, 1990).
 2.
 By importing categories, attributes, and values from an existing database or databases.
 DBPEDIA was built by importing structured facts from Wikipedia (Bizer et al., 2007).
 3.
 By parsing text documents and extracting information from them.
 TEXTRUNNER was built by reading a large corpus of Web pages (Banko and Etzioni, 2008).
 4.
 By enticing unskilled amateurs to enter commonsense knowledge.
 The OPENMIND system was built by volunteers who proposed facts in English (Singh et al., 2002; Chklovski and Gil, 2005).</template>
	</category>
	<category>
		<pattern>* GIVE * SSTRICT * DEFINITIONS * CATEGORIES *</pattern>
		<template>An object is a triangle if and only if it is a polygon with three sides.</template>
	</category>
	<category>
		<pattern>* WHAT * NATURAL KIND * CATEGORIES *</pattern>
		<template>Categories have no clear-cut definition.</template>
	</category>
	<category>
		<pattern>* NATURAL KIND * CATEGORIES *</pattern>
		<template>Categories have no clear-cut definition.</template>
	</category>
	<category>
		<pattern>* GIVE * NATURAL KIND * CATEGORIES *</pattern>
		<template>For example,tomatoes tend to be a dull scarlet; roughly spherical; with an indentation at the top where the stem was; about two to four inches in diameter; with a thin but tough skin; and with flesh, seeds, and juice inside.
 There is, however, variation: some tomatoes are yellow or orange, unripe tomatoes are green, some are smaller or larger than average, and cherry tomatoes are uniformly small.</template>
	</category>
	<category>
		<pattern>* WHAT * HAVING * RATHER THAN * A COMPLETE * DEFINITION * TOMATOES *</pattern>
		<template>We have a set of features that serves to identify objects that are clearly typical tomatoes, but might not be able to decide for other objects.</template>
	</category>
	<category>
		<pattern>* WHAT * HAVING * RATHER THAN * A COMPLETE * DEFINITION * TOMATOES *</pattern>
		<template>We have a set of features that serves to identify objects that are clearly typical tomatoes, but might not be able to decide for other objects.</template>
	</category>
	<category>
		<pattern>* WHAT * POSES * PROBLEM * LOGICAL AGENT *</pattern>
		<template>The agent cannot be sure that an object it has perceived is a certain object, and even if it were sure, it could not be certain which of the properties of typical certain objects this one has.</template>
	</category>
	<category>
		<pattern>* GIVE * PROBLEM * INEVITABLE CONSEQUENCE * OPERATING * PARTIALLY * OBSERVABLE * ENVIRONMENTS *</pattern>
		<template>There is, however, variation: some tomatoes are yellow or orange, unripe tomatoes are green, some are smaller or larger than average, and cherry tomatoes are uniformly small.
 Rather than having a complete definition of tomatoes, we have a set of features that serves to identify objects that are clearly typical tomatoes, but might not be able to decide for other objects.The agent cannot be sure that an object it has perceived is a tomato, and even if it were sure, it could not be certain which of the properties of typical tomatoes this one has.</template>
	</category>
	<category>
		<pattern>* GIVE * SEPARATE * TRUE * ALL INSTANCES * CATEGORY * TRUE ONLY * TYPICAL INSTANCES *</pattern>
		<template>So in addition to the category Tomatoes , we will also have the category Typical (Tomatoes).
 Here, the Typical function maps a category to the subclass that contains only typical instances: Typical (c) part of c.
 Most knowledge about natural kinds will actually be about their typical instances: xE Typical (Tomatoes ) -> Red (x) xor Round (x).</template>
	</category>
	<category>
		<pattern>* WHAT * WITTGENSTEIN * USED *</pattern>
		<template>Wittgenstein used the example of games to show that members of a category shared "family resemblances" rather than necessary and sufficient characteristics: what strict definition encompasses chess, tag, solitaire, and dodgeball?</template>
	</category>
	<category>
		<pattern>* WHO * CHALLENGE * THE UTILITY * NOTION * STRICT * DEFINITION *</pattern>
		<template>The utility of the notion of strict definition was also challenged by Quine.</template>
	</category>
	<category>
		<pattern>* WHAT * Quine * POINTED *</pattern>
		<template>He pointed out that even the definition of "bachelor" as an unmarried adult male is suspect; one might, for example, question a statement such as "the Pope is a bachelor.".</template>
	</category>
	<category>
		<pattern>* WHAT * Quine * DO *</pattern>
		<template>He pointed out that even the definition of "bachelor" as an unmarried adult male is suspect; one might, for example, question a statement such as "the Pope is a bachelor.".</template>
	</category>
	<category>
		<pattern>* HOW * TENSION * COULD * RESOLVED *</pattern>
		<template>The tension could perhaps be resolved by distinguishing between logical definitions suitable for internal knowledge representation and the more nuanced criteria for felicitous linguistic usage.</template>
	</category>
	<category>
		<pattern>* HOW * FAILURES * LINGUISTIC * MODIFYING * INTERNAL * DEFINITIONS *</pattern>
		<template>It is also possible that failures of linguistic usage serve as feedback for modifying internal definitions, so that filtering becomes unnecessary.</template>
	</category>
	<category>
		<pattern>* HOW * FAILURES * LINGUISTIC * MODIFYING * INTERNAL * DEFINITIONS *</pattern>
		<template>It is also possible that failures of linguistic usage serve as feedback for modifying internal definitions, so that filtering becomes unnecessary.</template>
	</category>
	<category>
		<pattern>* WHEN * FILTERING * BECOMES * UNNECESSARY *</pattern>
		<template>When failures of linguistic usage serve as feedback for modifying internal definitions.</template>
	</category>
	<category>
		<pattern>* HELLO *</pattern>
		<template>Well, hello!</template>
	</category>
	<category>
		<pattern>* TRUTH MAINTENANCE *</pattern>
		<template>Truth maintenance systems also provide a mechanism for generating explanations.
 Technically, an explanation of a sentence P is a set of sentences E such that E entails P.
 If the sentences in E are already known to be true, then E simply provides a sufficient basis for proving that P must be the case.</template>
	</category>
	<category>
		<pattern>* ENCODE * KNOWLEDGE *</pattern>
		<template>we put together all we have learned to encode knowledge for a shopping research agent that helps a buyer find product offers on the Internet</template>
	</category>
	<category>
		<pattern>* WHAT * SHOPPING AGENT *</pattern>
		<template>The shopping agent is given a product description by the buyer and has the task of producing a list of Web pages that offer such a product for sale, and ranking which offers are best</template>
	</category>
	<category>
		<pattern>* SHOPPING AGENT'S ENVIRONMENT *</pattern>
		<template>The shopping agent's environment is the entireWorldWideWeb in its full complexity- not a toy simulated environment.
 The agent's percepts are Web pages, but whereas a human Web user would see pages displayed as an array of pixels on a screen, the shopping agent will perceive a page as a character string consisting of ordinary words interspersed with formatting commands in the HTML markup language</template>
	</category>
	<category>
		<pattern>* PERCEPTION PROBLEM *</pattern>
		<template>The perception problem for the shopping agent involves extracting useful information from percepts of this kind.</template>
	</category>
	<category>
		<pattern>* AGENT FIRST TASK *</pattern>
		<template>The agent's first task is to collect product offers that are relevant to a query.
 If the query is laptops, then a Web page with a review of the latest high-end laptop would be relevant, but if it doesn't provide a way to buy, it isn't an offer.
 For now, we can say a page is an offer if it contains the words "buy" or price or add to cart within an HTML link or form on thepage.</template>
	</category>
	<category>
		<pattern>* FOLLOWING LINKS *</pattern>
		<template>The strategy is to start at the homepage of an online store and consider all pages that can be reached by following relevant links.11 The agent will have knowledge of a number of stores,These stores classify their goods into product categories, and provide links to the major categories from their home page</template>
	</category>
	<category>
		<pattern>* MINOR CATEGORIES *</pattern>
		<template>Minor categories can be reached through a chain of relevant links, and eventually we will reach offers.
 In other words, a page is relevant to the query if it can be reached by a chain of zero or more relevant category links from a store's home page, and then from one more link to the product offer</template>
	</category>
	<category>
		<pattern>* PREDICATE LINK(FROM, TO) *</pattern>
		<template>the predicate Link(from, to) means that there is a hyperlink from the from URL to the to URL.</template>
	</category>
	<category>
		<pattern>* PREDICATE LINK *</pattern>
		<template>the predicate Link(from, to) means that there is a hyperlink from the from URL to the to URL.</template>
	</category>
	<category>
		<pattern>* WHAT * COUNTS * RELEVANTCHAIN *</pattern>
		<template>To define what counts as a RelevantChain, we need to follow not just any old hyperlinks, but only those links whose associated anchor text indicates that the link is relevant to the product query.
 For this, we use LinkText(from, to, text) to mean that there is a link between from and to with text as the anchor text</template>
	</category>
	<category>
		<pattern>* WHAT * RELEVANTCHAIN *</pattern>
		<template>To define what counts as a RelevantChain, we need to follow not just any old hyperlinks, but only those links whose associated anchor text indicates that the link is relevant to the product query.
 For this, we use LinkText(from, to, text) to mean that there is a link between from and to with text as the anchor text</template>
	</category>
	<category>
		<pattern>* CHAIN OF LINKS *</pattern>
		<template>A chain of links between two URLs, start and end, is relevant to a description d if the anchor text of each link is a relevant category name for d.
 The existence of the chain itself is determined by a recursive definition, with the empty chain (start =end)</template>
	</category>
	<category>
		<pattern>* RELEVANT LINKS *</pattern>
		<template>It will not be feasible to list all possible shopping categories, because a buyer could always come up with some new desire and manufacturers will always come out with new products to satisfy them (electric kneecap warmers?).
 Nonetheless, an ontology of about a thousand categories will serve as a very useful tool for most buyers.</template>
	</category>
	<category>
		<pattern>* PRODUCT HIERARCHY *</pattern>
		<template>In addition to the product hierarchy itself, we also need to have a rich vocabulary of names for categories.
 Life would be much easier if there were a one-to-one correspondence between categories and the character strings that name them</template>
	</category>
	<category>
		<pattern>* SYNONYMY * AMBIGUITY *</pattern>
		<template>Synonymy and ambiguity can cause a significant increase in the number of paths that the agent has to follow, and can sometimes make it difficult to determine whether a given page is indeed relevant.
 A much more serious problem is the very broad range of descriptions that a user can type and category names that a store can use</template>
	</category>
	<category>
		<pattern>* PROCEDURAL ATTACHMENT *</pattern>
		<template>In this way, it appears to the inference engine as if the entire Web is inside the knowledge base.
 This is an example of a general technique called procedural attachment</template>
	</category>
	<category>
		<pattern>* WHAT * WRAPPERS *</pattern>
		<template>A common WRAPPER way of dealing with this problem is to use programs called wrappers to extract information from a page</template>
	</category>
	<category>
		<pattern>* HIERARCHY * WRAPPERS *</pattern>
		<template>A hierarchy of wrappers would be applied to a page: a very general one to extract dates and prices, a more specific one to extract attributes for computer-related products, and if necessary a site-specific one that knows the format of a particular store.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * NAME PREDICATE *</pattern>
		<template>Name("laptops", LaptopComputers )</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * BROAD RANGE * DESCRIPTIONS * USER *</pattern>
		<template>For example, the link might say "laptop" when the knowledge base has only "laptops" or the user might ask for "a computer I can fit on the tray table of an economy-class airline seat."</template>
	</category>
	<category>
		<pattern>* HELLO *</pattern>
		<template>Well, hello!</template>
	</category>
	<category>
		<pattern>* WHO ARE YOU *</pattern>
		<template>I'm Faseeh</template>
	</category>
	<category>
		<pattern>* WHAT IS A MODEL *</pattern>
		<template>a model contains a set of objects and an interpretation that maps each name to the appropriate object, relation, or function.</template>
	</category>
	<category>
		<pattern>* WHAT * MODEL *</pattern>
		<template>a model contains a set of objects and an interpretation that maps each name to the appropriate object, relation, or function.</template>
	</category>
	<category>
		<pattern>* MODEL *</pattern>
		<template>a model contains a set of objects and an interpretation that maps each name to the appropriate object, relation, or function.</template>
	</category>
	<category>
		<pattern>* MODEL *</pattern>
		<template>a model contains a set of objects and an interpretation that maps each name to the appropriate object, relation, or function.</template>
	</category>
	<category>
		<pattern>* WHAT IS LOGICAL OMNISCIENCE *</pattern>
		<template>if an agent knows a set of axioms, then it knows all consequences of those axioms.</template>
	</category>
	<category>
		<pattern>* WHAT * LOGICAL OMNISCIENCE *</pattern>
		<template>if an agent knows a set of axioms, then it knows all consequences of those axioms.</template>
	</category>
	<category>
		<pattern>* LOGICAL OMNISCIENCE *</pattern>
		<template>if an agent knows a set of axioms, then it knows all consequences of those axioms.</template>
	</category>
	<category>
		<pattern>* LOGICAL OMNISCIENCE *</pattern>
		<template>if an agent knows a set of axioms, then it knows all consequences of those axioms.</template>
	</category>
	<category>
		<pattern>* WHAT ARE CATEGORIES *</pattern>
		<template>Categories are the primary building blocks of large-scale knowledge representation schemes.</template>
	</category>
	<category>
		<pattern>* WHAT * CATEGORIES *</pattern>
		<template>Categories are the primary building blocks of large-scale knowledge representation schemes.</template>
	</category>
	<category>
		<pattern>* CATEGORIES *</pattern>
		<template>Categories are the primary building blocks of large-scale knowledge representation schemes.</template>
	</category>
	<category>
		<pattern>* CATEGORIES *</pattern>
		<template>Categories are the primary building blocks of large-scale knowledge representation schemes.</template>
	</category>
	<category>
		<pattern>* WHAT ARE SEMANTIC NETWORKS *</pattern>
		<template>semantic networks provide graphical aids for visualizing a knowledge base and efficient algorithms for inferring properties of an object on the basis of its category membership.</template>
	</category>
	<category>
		<pattern>* WHAT * SEMANTIC NETWORKS *</pattern>
		<template>semantic networks provide graphical aids for visualizing a knowledge base and efficient algorithms for inferring properties of an object on the basis of its category membership.</template>
	</category>
	<category>
		<pattern>* SEMANTIC NETWORKS *</pattern>
		<template>semantic networks provide graphical aids for visualizing a knowledge base and efficient algorithms for inferring properties of an object on the basis of its category membership.</template>
	</category>
	<category>
		<pattern>* SEMANTIC NETWORKS *</pattern>
		<template>semantic networks provide graphical aids for visualizing a knowledge base and efficient algorithms for inferring properties of an object on the basis of its category membership.</template>
	</category>
	<category>
		<pattern>* WHAT ARE DESCRIPTION LOGICS *</pattern>
		<template>description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* WHAT * DESCRIPTION LOGICS *</pattern>
		<template>description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* WHAT * DESCRIPTION LOGICS *</pattern>
		<template>description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* DESCRIPTION LOGICS *</pattern>
		<template>description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* DESCRIPTION LOGICS *</pattern>
		<template>description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* WHAT IS MULTIPLE INHERITANCE *</pattern>
		<template>when an object can belong to more than one category or when a category can be a subset of more than one other category.</template>
	</category>
	<category>
		<pattern>* WHAT * MULTIPLE INHERITANCE *</pattern>
		<template>when an object can belong to more than one category or when a category can be a subset of more than one other category.</template>
	</category>
	<category>
		<pattern>* MULTIPLE INHERITANCE *</pattern>
		<template>when an object can belong to more than one category or when a category can be a subset of more than one other category.</template>
	</category>
	<category>
		<pattern>* MULTIPLE INHERITANCE *</pattern>
		<template>when an object can belong to more than one category or when a category can be a subset of more than one other category.</template>
	</category>
	<category>
		<pattern>* WHAT IS PROCEDURAL ATTACHMENT *</pattern>
		<template>Procedural attachment is a technique whereby a query about (or sometimes an assertion of) a certain relation results in a call to a special procedure designed for that relation rather than a general inference algorithm.</template>
	</category>
	<category>
		<pattern>* WHAT * PROCEDURAL ATTACHMENT *</pattern>
		<template>Procedural attachment is a technique whereby a query about (or sometimes an assertion of) a certain relation results in a call to a special procedure designed for that relation rather than a general inference algorithm.</template>
	</category>
	<category>
		<pattern>* PROCEDURAL ATTACHMENT *</pattern>
		<template>Procedural attachment is a technique whereby a query about (or sometimes an assertion of) a certain relation results in a call to a special procedure designed for that relation rather than a general inference algorithm.</template>
	</category>
	<category>
		<pattern>* PROCEDURAL ATTACHMENT *</pattern>
		<template>Procedural attachment is a technique whereby a query about (or sometimes an assertion of) a certain relation results in a call to a special procedure designed for that relation rather than a general inference algorithm.</template>
	</category>
	<category>
		<pattern>* NAME ONE OF THE MOST IMPORTANT ASPECTS OF SEMANTIC NETWORKS *</pattern>
		<template>their ability to represent values for categories.</template>
	</category>
	<category>
		<pattern>* ONE OF THE MOST IMPORTANT ASPECTS OF SEMANTIC NETWORKS *</pattern>
		<template>their ability to represent values for categories.</template>
	</category>
	<category>
		<pattern>* IMPORTANT ASPECTS OF SEMANTIC NETWORKS *</pattern>
		<template>their ability to represent values for categories.</template>
	</category>
	<category>
		<pattern>* IMPORTANT ASPECTS OF SEMANTIC NETWORKS *</pattern>
		<template>their ability to represent values for categories.</template>
	</category>
	<category>
		<pattern>* IMPORTANT ASPECTS * SEMANTIC NETWORKS *</pattern>
		<template>their ability to represent values for categories.</template>
	</category>
	<category>
		<pattern>* IMPORTANT ASPECTS * SEMANTIC NETWORKS *</pattern>
		<template>their ability to represent values for categories.</template>
	</category>
	<category>
		<pattern>* WHAT ARE DESCRIPTION LOGICS *</pattern>
		<template>description logics are notations that are designed to make it easier to describe definitions and properties of categories.</template>
	</category>
	<category>
		<pattern>* DESCRIPTION LOGICS *</pattern>
		<template>description logics are notations that are designed to make it easier to describe definitions and properties of categories.</template>
	</category>
	<category>
		<pattern>* WHAT * DESCRIPTION LOGICS *</pattern>
		<template>description logics are notations that are designed to make it easier to describe definitions and properties of categories.</template>
	</category>
	<category>
		<pattern>* DESCRIPTION LOGICS *</pattern>
		<template>description logics are notations that are designed to make it easier to describe definitions and properties of categories.</template>
	</category>
	<category>
		<pattern>* WHY DID DESCRIPTION LOGIC SYSTEMS EVOLVE *</pattern>
		<template>Description logic systems evolved from semantic networks in response to pressure to formalize what the networks mean while retaining the emphasis on taxonomic structure as an organizing principle.</template>
	</category>
	<category>
		<pattern>* WHY * DESCRIPTION LOGIC SYSTEMS EVOLVE *</pattern>
		<template>Description logic systems evolved from semantic networks in response to pressure to formalize what the networks mean while retaining the emphasis on taxonomic structure as an organizing principle.</template>
	</category>
	<category>
		<pattern>* DESCRIPTION LOGIC SYSTEMS EVOLVE *</pattern>
		<template>Description logic systems evolved from semantic networks in response to pressure to formalize what the networks mean while retaining the emphasis on taxonomic structure as an organizing principle.</template>
	</category>
	<category>
		<pattern>* DESCRIPTION LOGIC SYSTEMS EVOLVE *</pattern>
		<template>Description logic systems evolved from semantic networks in response to pressure to formalize what the networks mean while retaining the emphasis on taxonomic structure as an organizing principle.</template>
	</category>
	<category>
		<pattern>* DESCRIPTION LOGIC SYSTEMS *</pattern>
		<template>Description logic systems evolved from semantic networks in response to pressure to formalize what the networks mean while retaining the emphasis on taxonomic structure as an organizing principle.</template>
	</category>
	<category>
		<pattern>* WHAT IS SUBSUMPTION *</pattern>
		<template>checking if one category is a subset of another by comparing their definitions.</template>
	</category>
	<category>
		<pattern>* WHAT * SUBSUMPTION *</pattern>
		<template>checking if one category is a subset of another by comparing their definitions.</template>
	</category>
	<category>
		<pattern>* SUBSUMPTION *</pattern>
		<template>checking if one category is a subset of another by comparing their definitions.</template>
	</category>
	<category>
		<pattern>* SUBSUMPTION *</pattern>
		<template>checking if one category is a subset of another by comparing their definitions.</template>
	</category>
	<category>
		<pattern>* WHAT IS CLASSIFICATION *</pattern>
		<template>checking whether an object belongs to a category.</template>
	</category>
	<category>
		<pattern>* WHAT * CLASSIFICATION *</pattern>
		<template>checking whether an object belongs to a category.</template>
	</category>
	<category>
		<pattern>* CLASSIFICATION *</pattern>
		<template>checking whether an object belongs to a category.</template>
	</category>
	<category>
		<pattern>* CLASSIFICATION *</pattern>
		<template>checking whether an object belongs to a category.</template>
	</category>
	<category>
		<pattern>* WHAT IS CONSISTENCY *</pattern>
		<template>checking whether the membership criteria are logically satisfiable.</template>
	</category>
	<category>
		<pattern>* WHAT * CONSISTENCY *</pattern>
		<template>checking whether the membership criteria are logically satisfiable.</template>
	</category>
	<category>
		<pattern>* CONSISTENCY *</pattern>
		<template>checking whether the membership criteria are logically satisfiable.</template>
	</category>
	<category>
		<pattern>* CONSISTENCY *</pattern>
		<template>checking whether the membership criteria are logically satisfiable.</template>
	</category>
	<category>
		<pattern>* WHAT IS CIRCUMSCRIPTION *</pattern>
		<template>Circumscription can be seen as a more powerful and precise version of the closed world assumption.
 The idea is to specify particular predicates that are assumed to be "as false as possible"-that is, false for every object except those for which they are known to be true.
 Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* WHAT * CIRCUMSCRIPTION *</pattern>
		<template>Circumscription can be seen as a more powerful and precise version of the closed world assumption.
 The idea is to specify particular predicates that are assumed to be "as false as possible"-that is, false for every object except those for which they are known to be true.
 Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* CIRCUMSCRIPTION *</pattern>
		<template>Circumscription can be seen as a more powerful and precise version of the closed world assumption.
 The idea is to specify particular predicates that are assumed to be "as false as possible"-that is, false for every object except those for which they are known to be true.
 Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* CIRCUMSCRIPTION *</pattern>
		<template>Circumscription can be seen as a more powerful and precise version of the closed world assumption.
 The idea is to specify particular predicates that are assumed to be "as false as possible"-that is, false for every object except those for which they are known to be true.
 Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* NAME A THE STANDARD EXAMPLE FOR WHICH MULTIPLE INHERITANCE IS PROBLEMATIC *</pattern>
		<template>"Nixon diamond".</template>
	</category>
	<category>
		<pattern>* NAME * EXAMPLE FOR WHICH MULTIPLE INHERITANCE IS PROBLEMATIC *</pattern>
		<template>"Nixon diamond".</template>
	</category>
	<category>
		<pattern>* EXAMPLE * MULTIPLE INHERITANCE * PROBLEMATIC *</pattern>
		<template>"Nixon diamond".</template>
	</category>
	<category>
		<pattern>* WHICH MULTIPLE INHERITANCE IS PROBLEMATIC *</pattern>
		<template>"Nixon diamond".</template>
	</category>
	<category>
		<pattern>* MULTIPLE INHERITANCE * PROBLEMATIC *</pattern>
		<template>"Nixon diamond".</template>
	</category>
	<category>
		<pattern>* WHAT IS DEFAULT LOGIC *</pattern>
		<template>Default logic is a formalism in which default rules can be written to generate contingent, nonmonotonic conclusions.</template>
	</category>
	<category>
		<pattern>* WHAT * DEFAULT LOGIC *</pattern>
		<template>Default logic is a formalism in which default rules can be written to generate contingent, nonmonotonic conclusions.</template>
	</category>
	<category>
		<pattern>* WHAT * DEFAULT LOGIC *</pattern>
		<template>Default logic is a formalism in which default rules can be written to generate contingent, nonmonotonic conclusions.</template>
	</category>
	<category>
		<pattern>* DEFAULT LOGIC *</pattern>
		<template>Default logic is a formalism in which default rules can be written to generate contingent, nonmonotonic conclusions.</template>
	</category>
	<category>
		<pattern>* DEFINE EXTENSION OF A DEFAULT THEORY *</pattern>
		<template>extension of a default theory is a maximal set of consequences of the theory.
 That is, an extension S consists of the original known facts and a set of conclusions from the default rules, such that no additional conclusions can be drawn from S and the justifications of every default conclusion in S are consistent with S.</template>
	</category>
	<category>
		<pattern>* DEFINE EXTENSION * DEFAULT THEORY *</pattern>
		<template>extension of a default theory is a maximal set of consequences of the theory.
 That is, an extension S consists of the original known facts and a set of conclusions from the default rules, such that no additional conclusions can be drawn from S and the justifications of every default conclusion in S are consistent with S.</template>
	</category>
	<category>
		<pattern>* EXTENSION * DEFAULT THEORY *</pattern>
		<template>extension of a default theory is a maximal set of consequences of the theory.
 That is, an extension S consists of the original known facts and a set of conclusions from the default rules, such that no additional conclusions can be drawn from S and the justifications of every default conclusion in S are consistent with S.</template>
	</category>
	<category>
		<pattern>* EXTENSION * DEFAULT THEORY *</pattern>
		<template>extension of a default theory is a maximal set of consequences of the theory.
 That is, an extension S consists of the original known facts and a set of conclusions from the default rules, such that no additional conclusions can be drawn from S and the justifications of every default conclusion in S are consistent with S.</template>
	</category>
	<category>
		<pattern>* DEFINE * DEFAULT THEORY *</pattern>
		<template>extension of a default theory is a maximal set of consequences of the theory.
 That is, an extension S consists of the original known facts and a set of conclusions from the default rules, such that no additional conclusions can be drawn from S and the justifications of every default conclusion in S are consistent with S.</template>
	</category>
	<category>
		<pattern>* MENTION THE MAIN TRADEOFF INVOLVED WHEN TAKING DECISIONS *</pattern>
		<template>compare the strengths of belief in the outcomes of different actions, and the costs of making a wrong decision.</template>
	</category>
	<category>
		<pattern>* MENTION * MAIN TRADEOFF INVOLVED WHEN TAKING DECISIONS *</pattern>
		<template>compare the strengths of belief in the outcomes of different actions, and the costs of making a wrong decision.</template>
	</category>
	<category>
		<pattern>* MENTION * TRADEOFF INVOLVED * TAKING DECISIONS *</pattern>
		<template>compare the strengths of belief in the outcomes of different actions, and the costs of making a wrong decision.</template>
	</category>
	<category>
		<pattern>* MENTION * MAIN TRADEOFF INVOLVED * TAKING DECISIONS *</pattern>
		<template>compare the strengths of belief in the outcomes of different actions, and the costs of making a wrong decision.</template>
	</category>
	<category>
		<pattern>* WHAT IS BELIEF REVISION *</pattern>
		<template>many of the inferences drawn by a knowledge representation system will have only default status, rather than being absolutely certain.
 Inevitably, some of these inferred facts will turn out to be wrong and will have to be retracted in the face of new information.
 This process is called belief revision.</template>
	</category>
	<category>
		<pattern>* WHAT * BELIEF REVISION *</pattern>
		<template>many of the inferences drawn by a knowledge representation system will have only default status, rather than being absolutely certain.
 Inevitably, some of these inferred facts will turn out to be wrong and will have to be retracted in the face of new information.
 This process is called belief revision.</template>
	</category>
	<category>
		<pattern>* BELIEF REVISION *</pattern>
		<template>many of the inferences drawn by a knowledge representation system will have only default status, rather than being absolutely certain.
 Inevitably, some of these inferred facts will turn out to be wrong and will have to be retracted in the face of new information.
 This process is called belief revision.</template>
	</category>
	<category>
		<pattern>* WHAT * BELIEF REVISION *</pattern>
		<template>many of the inferences drawn by a knowledge representation system will have only default status, rather than being absolutely certain.
 Inevitably, some of these inferred facts will turn out to be wrong and will have to be retracted in the face of new information.
 This process is called belief revision.</template>
	</category>
	<category>
		<pattern>* BELIEF REVISION *</pattern>
		<template>many of the inferences drawn by a knowledge representation system will have only default status, rather than being absolutely certain.
 Inevitably, some of these inferred facts will turn out to be wrong and will have to be retracted in the face of new information.
 This process is called belief revision.</template>
	</category>
	<category>
		<pattern>* WHAT IS BELIEF UPDATE *</pattern>
		<template>belief update, which occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.
 Belief update combines belief revision with reasoning about time and change; it is also related to the process of filtering.</template>
	</category>
	<category>
		<pattern>* WHAT * BELIEF UPDATE *</pattern>
		<template>belief update, which occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.
 Belief update combines belief revision with reasoning about time and change; it is also related to the process of filtering.</template>
	</category>
	<category>
		<pattern>* WHAT * BELIEF UPDATE *</pattern>
		<template>belief update, which occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.
 Belief update combines belief revision with reasoning about time and change; it is also related to the process of filtering.</template>
	</category>
	<category>
		<pattern>* BELIEF UPDATE *</pattern>
		<template>belief update, which occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.
 Belief update combines belief revision with reasoning about time and change; it is also related to the process of filtering.</template>
	</category>
	<category>
		<pattern>* BELIEF UPDATE *</pattern>
		<template>belief update, which occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.
 Belief update combines belief revision with reasoning about time and change; it is also related to the process of filtering.</template>
	</category>
	<category>
		<pattern>* DESCRIBE ONE APPROACH TO TRUTH MAINTENANCE *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.</template>
	</category>
	<category>
		<pattern>* DESCRIBE ONE APPROACH * TRUTH MAINTENANCE *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.</template>
	</category>
	<category>
		<pattern>* APPROACH TO TRUTH MAINTENANCE *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.</template>
	</category>
	<category>
		<pattern>* DESCRIBE * APPROACH * MAINTENANCE *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.</template>
	</category>
	<category>
		<pattern>* DESCRIBE * APPROACH * MAINTENANCE *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.</template>
	</category>
	<category>
		<pattern>* APPROACH * TRUTH MAINTENANCE *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.</template>
	</category>
	<category>
		<pattern>* WHAT IS A MORE EFFICIENT APPROACH TO TRUTH MAINTENANCE *</pattern>
		<template>justification-based truth maintenance system( JTMS).</template>
	</category>
	<category>
		<pattern>* WHAT * MORE EFFICIENT APPROACH TO TRUTH MAINTENANCE *</pattern>
		<template>justification-based truth maintenance system( JTMS).</template>
	</category>
	<category>
		<pattern>* WHAT * EFFICIENT APPROACH * MAINTENANCE *</pattern>
		<template>justification-based truth maintenance system( JTMS).</template>
	</category>
	<category>
		<pattern>* MORE EFFICIENT APPROACH * TRUTH MAINTENANCE *</pattern>
		<template>justification-based truth maintenance system( JTMS).</template>
	</category>
	<category>
		<pattern>* WHAT * EFFICIENT APPROACH * MAINTENANCE *</pattern>
		<template>justification-based truth maintenance system( JTMS).</template>
	</category>
	<category>
		<pattern>* EFFICIENT APPROACH * MAINTENANCE *</pattern>
		<template>justification-based truth maintenance system( JTMS).</template>
	</category>
	<category>
		<pattern>* WHAT IS JUSTIFICATION-BASED TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.
 In general, a sentence can have any number of justifications.
 Justifications make retraction efficient.</template>
	</category>
	<category>
		<pattern>* WHAT * JUSTIFICATION-BASED TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.
 In general, a sentence can have any number of justifications.
 Justifications make retraction efficient.</template>
	</category>
	<category>
		<pattern>* WHAT * JUSTIFICATION-BASED * MAINTENANCE SYSTEM *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.
 In general, a sentence can have any number of justifications.
 Justifications make retraction efficient.</template>
	</category>
	<category>
		<pattern>* JUSTIFICATION-BASED * MAINTENANCE SYSTEM *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.
 In general, a sentence can have any number of justifications.
 Justifications make retraction efficient.</template>
	</category>
	<category>
		<pattern>* JUSTIFICATION-BASED * MAINTENANCE SYSTEM *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.
 In general, a sentence can have any number of justifications.
 Justifications make retraction efficient.</template>
	</category>
	<category>
		<pattern>* WHAT IS THE TECHNICAL DEFINITION OF EXPLANATIONS *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.
 If the sentences in E are already known to be true, then E simply provides a sufficient baASSUMPTION sis for proving that P must be the case.</template>
	</category>
	<category>
		<pattern>* WHAT * TECHNICAL DEFINITION OF EXPLANATIONS *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.
 If the sentences in E are already known to be true, then E simply provides a sufficient baASSUMPTION sis for proving that P must be the case.</template>
	</category>
	<category>
		<pattern>* WHAT * TECHNICAL DEFINITION * EXPLANATIONS *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.
 If the sentences in E are already known to be true, then E simply provides a sufficient baASSUMPTION sis for proving that P must be the case.</template>
	</category>
	<category>
		<pattern>* DEFINITION * EXPLANATIONS *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.
 If the sentences in E are already known to be true, then E simply provides a sufficient baASSUMPTION sis for proving that P must be the case.</template>
	</category>
	<category>
		<pattern>* TECHNICAL DEFINITION * EXPLANATIONS *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.
 If the sentences in E are already known to be true, then E simply provides a sufficient baASSUMPTION sis for proving that P must be the case.</template>
	</category>
	<category>
		<pattern>* WHAT IS SYNONYMY *</pattern>
		<template>two names for the same category, such as 'laptop computers' and 'laptops'.</template>
	</category>
	<category>
		<pattern>* WHAT * SYNONYMY *</pattern>
		<template>two names for the same category, such as 'laptop computers' and 'laptops'.</template>
	</category>
	<category>
		<pattern>* WHAT * SYNONYMY *</pattern>
		<template>two names for the same category, such as 'laptop computers' and 'laptops'.</template>
	</category>
	<category>
		<pattern>* SYNONYMY *</pattern>
		<template>two names for the same category, such as 'laptop computers' and 'laptops'.</template>
	</category>
	<category>
		<pattern>* WHAT IS AMBIGUITY *</pattern>
		<template>one name for two or more different categories.</template>
	</category>
	<category>
		<pattern>* WHAT * AMBIGUITY *</pattern>
		<template>one name for two or more different categories.</template>
	</category>
	<category>
		<pattern>* WHAT * AMBIGUITY *</pattern>
		<template>one name for two or more different categories.</template>
	</category>
	<category>
		<pattern>* AMBIGUITY *</pattern>
		<template>one name for two or more different categories.</template>
	</category>
	<category>
		<pattern>* DEFINE THE FUNCTION OF WRAPPERS PROGRAMS *</pattern>
		<template>extract information from a page, used to deal with the problem of extracting e relevant information such as price, speed, disk size, weight, and so on from the offer pages which can be a difficult task with real Web pages.Typically, a hierarchy of wrappers would be applied to a page: a very general one to extract dates and prices, a more specific one to extract attributes for computer-related products, and if necessary a site-specific one that knows the format of a particular store.</template>
	</category>
	<category>
		<pattern>* DEFINE * FUNCTION * WRAPPERS PROGRAMS *</pattern>
		<template>extract information from a page, used to deal with the problem of extracting e relevant information such as price, speed, disk size, weight, and so on from the offer pages which can be a difficult task with real Web pages.Typically, a hierarchy of wrappers would be applied to a page: a very general one to extract dates and prices, a more specific one to extract attributes for computer-related products, and if necessary a site-specific one that knows the format of a particular store.</template>
	</category>
	<category>
		<pattern>* FUNCTION * WRAPPERS PROGRAMS *</pattern>
		<template>extract information from a page, used to deal with the problem of extracting e relevant information such as price, speed, disk size, weight, and so on from the offer pages which can be a difficult task with real Web pages.Typically, a hierarchy of wrappers would be applied to a page: a very general one to extract dates and prices, a more specific one to extract attributes for computer-related products, and if necessary a site-specific one that knows the format of a particular store.</template>
	</category>
	<category>
		<pattern>* FUNCTION * WRAPPERS PROGRAMS *</pattern>
		<template>extract information from a page, used to deal with the problem of extracting e relevant information such as price, speed, disk size, weight, and so on from the offer pages which can be a difficult task with real Web pages.Typically, a hierarchy of wrappers would be applied to a page: a very general one to extract dates and prices, a more specific one to extract attributes for computer-related products, and if necessary a site-specific one that knows the format of a particular store.</template>
	</category>
	<category>
		<pattern>* EXHAUSTIVE DECOMPOSITION * DISJOINT * PARTITION *</pattern>
		<template>The following examples illustrate these three concepts: Disjoint ({Animals, Vegetables}) ExhaustiveDecomposition ({Americans, Canadians, Mexicans},NorthAmericans) Partition({Males, Females}, Animals) .</template>
	</category>
	<category>
		<pattern>* PHYSICAL COMPOSITION *</pattern>
		<template>The idea that one object can be part of another is a familiar one.
 One's nose is part of one's head, Romania is part of Europe, and this chapter is part of this book.
 We use the general PartOf relation to say that one thing is part of another.
 Objects can be grouped into PartOf hierarchies, reminiscent of the Subset hierarchy: PartOf (Bucharest, Romania) PartOf (Romania, EasternEurope) PartOf (EasternEurope, Europe) PartOf (Europe, Earth).</template>
	</category>
	<category>
		<pattern>* AI * INTERACTION * WORLD *</pattern>
		<template>Although interaction with the world takes place at the level of individual objects, much reasoning takes place at the level of categories.
 For example, a shopper would normally have the goal of buying a basketball, rather than a particular basketball such as BB .</template>
	</category>
	<category>
		<pattern>* REPRESENTING * CATEGORIES * FIRST * ORDER * LOGIC *</pattern>
		<template>Although interaction with the world takes place at the level of individual objects, much reasoning takes place at the level of categories.
 For example, a shopper would normally have the goal of buying a basketball, rather than a particular basketball such as BB .</template>
	</category>
	<category>
		<pattern>* WHAT * UPPER ONTOLOGY *</pattern>
		<template>The general framework of concepts.</template>
	</category>
	<category>
		<pattern>* WHAT * ONTOLOGICAL ENGINEERING *</pattern>
		<template>Representing abstract concepts such as Events, Time, Physical Objects, and Beliefs that occur in many different domains.</template>
	</category>
	<category>
		<pattern>* HOW * INTRODUCE * CLASSES *</pattern>
		<template>by describing the technology (TTL, CMOS, and so on) as well as the input output specification.
 If we wanted to discuss reliability or diagnosis, we would include the possibility that the structure of the circuit or the properties of the gates might change spontaneously.
 To account for stray capacitances, we would need to represent where the wires are on the board.</template>
	</category>
	<category>
		<pattern>* GENERAL-PURPOSE ONTOLOGY * DIFFER * SPECIAL-PURPOSE ONTOLOGIES *</pattern>
		<template>A general-purpose ontology should be applicable in more or less any special-purpose domain (with the addition of domain specific axioms).
 This means that no representational issue can be finessed or brushed under the carpet.
 In any sufficiently demanding domain, different areas of knowledge must be unified, because reasoning and problem solving could involve several areas simultaneously.
 A robot circuit-repair system, for instance, needs to reason about circuits in terms of electrical connectivity and physical layout, and about time, both for circuit timing analysis and estimating labor costs.
 The sentences describing time therefore must be capable of being combined with those describing spatial layout and must work equally well for nanoseconds and minutes and for angstroms and meters.</template>
	</category>
	<category>
		<pattern>* ROUTES * BUILD * EXISTING ONTOLOGIES *</pattern>
		<template>1.
 By a team of trained ontologist/logicians, who architect the ontology and write axioms.
 The CYC system was mostly built this way (Lenat and Guha, 1990).
 2.
 By importing categories, attributes, and values from an existing database or databases.
 DBPEDIA was built by importing structured facts from Wikipedia (Bizer et al., 2007).
 3.
 By parsing text documents and extracting information from them.
 TEXTRUNNER was built by reading a large corpus of Web pages (Banko and Etzioni, 2008).
 4.
 By enticing unskilled amateurs to enter commonsense knowledge.
 The OPENMIND system was built by volunteers who proposed facts in English (Singh et al., 2002; Chklovski and Gil, 2005).</template>
	</category>
	<category>
		<pattern>* WHAT * DEFINITION * REIFICATION *</pattern>
		<template>Turning a proposition into an object is called reification.</template>
	</category>
	<category>
		<pattern>* CATEGORIES * EXAMPLES *</pattern>
		<template>An object is a member of a category.
 BB9 belong to Basketballs.
 A category is a subclass of another category.
 Basketballs part of Balls.
 All members of a category have some properties.
 (xE Basketballs) -> Spherical(x).
 Members of a category can be recognized by some properties.
 Orange(x) xor Round(x) xor Diameter(x) = 9.5 xor xE Balls -> xE Basketballs.
 A category as a whole has some properties.
 Dogs part of DomesticatedSpecies</template>
	</category>
	<category>
		<pattern>* WHAT * DISJOINT CATEGORIES *</pattern>
		<template>two or more categories are disjoint if they have no members in common.</template>
	</category>
	<category>
		<pattern>* CHARACTERISTIC * CATEGORIES * COMPOSITE OBJECTS *</pattern>
		<template>Categories of composite objects are often characterized by structural relations among parts.</template>
	</category>
	<category>
		<pattern>* WHAT * LOGICAL MINIMIZATION *</pattern>
		<template>logical minimization means defining an object as the smallest one satisfying certain conditions.</template>
	</category>
	<category>
		<pattern>* WHEN * OBJECT * TRIANGLE *</pattern>
		<template>an object is a triangle if and only if it is a polygon with three sides.</template>
	</category>
	<category>
		<pattern>* WHAT * NATURAL KIND CATEGORIES *</pattern>
		<template>categories in the real world which have no clear-cut definition.</template>
	</category>
	<category>
		<pattern>* WHAT * MEASURES *</pattern>
		<template>The values that we assign for properties like e height, mass, cost, and so on.</template>
	</category>
	<category>
		<pattern>* WHAT * ASPECT * MEASURES *</pattern>
		<template>The most important aspect of measures is not the particular numerical values, but the fact that measures can be ordered.</template>
	</category>
	<category>
		<pattern>* WHAT * QUALITATIVE PHYSICS *</pattern>
		<template>a subfield of AI that investigates how to reason about physical systems without plunging into detailed equations and numerical simulations.</template>
	</category>
	<category>
		<pattern>* WHAT * INDIVIDUATION *</pattern>
		<template>division into distinct objects.</template>
	</category>
	<category>
		<pattern>* HOW * STUFF *</pattern>
		<template>begin with the obvious.
 We need to have as objects in our ontology at least the gross "lumps" of stuff we interact with.</template>
	</category>
	<category>
		<pattern>* WHAT * INTRINSIC PROPERTIES *</pattern>
		<template>they belong to the very substance of the object, rather than to the object as a whole.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * EXTRINSIC PROPERTIES *</pattern>
		<template>weight, length, shape, and so on.</template>
	</category>
	<category>
		<pattern>* WHY * SITUATION CALCULUS * LIMITE *</pattern>
		<template>it was designed to describe a world in which actions are discrete, instantaneous, and happen one at a time.
 Consider a continuous action, such as filling a bathtub.
 Situation calculus can say that the tub is empty before the action and full when the action is done, but it can't talk about what happens during the action.
 It also can't describe two actions happening at the same time.</template>
	</category>
	<category>
		<pattern>* WHAT * ACTION * CONNOTE *</pattern>
		<template>action connotes an agent</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT * CONNOTE *</pattern>
		<template>event connotes the possibility of agentless actions</template>
	</category>
	<category>
		<pattern>* WHAT * EVENT CALCULUS *</pattern>
		<template>an alternative formalism to situation calculus known as event calculus, which is based on points of time rather than on situations</template>
	</category>
	<category>
		<pattern>* WHAT * DISCRETE EVENTS *</pattern>
		<template>they have a definite structure.</template>
	</category>
	<category>
		<pattern>* WHAT * PROPOSITIONAL ATTITUDES *</pattern>
		<template>attitudes that an agent can have toward mental objects, attitudes such as Believes, Knows, Wants, Intends, and Informs.
 The difficulty is that these attitudes do not behave like "normal" predicates.</template>
	</category>
	<category>
		<pattern>* WHAT * REFERENTIAL TRANSPARENCY *</pattern>
		<template>it doesn't matter what REFERENTIAL TRANSPARENCY term a logic uses to refer to an object, what matters is the object that the term names.</template>
	</category>
	<category>
		<pattern>* WHAT * INHERITANCE MECHANISM * SEMANTIC NETWORKS * IMPLEMENTS *</pattern>
		<template>The inheritance mechanism in semantic networks implements the overriding of defaults in a simple and natural way.</template>
	</category>
	<category>
		<pattern>* WHAT * NONMONOTONICITY *</pattern>
		<template>For example, when one sees a car parked on the street, one is normally willing to believe that it has four wheels even though only three are visible.
 Now, probability theory can certainly provide a conclusion that the fourth wheel exists with high probability, yet, for most people, the possibility of the car's not having four wheels does not arise unless some new evidence presents itself.
 Thus, it seems that the four-wheel conclusion is reached by default, in the absence of any reason to doubt it.
 If new evidence arrives.
 for example, if one sees the owner carrying a wheel and notices that the car is jacked up then the conclusion can be retracted.
 This kind of reasoning is said to exhibit NONMONOTONICITY nonmonotonicity, because the set of beliefs does not grow monotonically over time as new evidence arrives.</template>
	</category>
	<category>
		<pattern>* WHAT * SIMPLE INTROSPECTION * SUGGESTS *</pattern>
		<template>Simple introspection suggests that these failures of monotonicity are widespread in commonsense reasoning.</template>
	</category>
	<category>
		<pattern>* WHY * NONMONOTONIC LOGICS * DEVISED *</pattern>
		<template>Nonmonotonic logics have been devised with modified notions of truth and entailment in order to capture the behaviour of nonmonotonicity.</template>
	</category>
	<category>
		<pattern>* WHAT * IDEA * CIRCUMSCRIPTION *</pattern>
		<template>The idea is to specify particular predicates that are assumed to be "as false as possible".
 that is, false for every object except those for which they are known to be true.</template>
	</category>
	<category>
		<pattern>* WHAT * CIRCUMSCRIPTION *</pattern>
		<template>The idea is to specify particular predicates that are assumed to be "as false as possible".
 that is, false for every object except those for which they are known to be true.</template>
	</category>
	<category>
		<pattern>* WHEN * CIRCUMSCRIPTION * MODEL * PREFERRED * ANOTHER *</pattern>
		<template>For circumscription, one model is preferred to another if it has fewer abnormal objects.</template>
	</category>
	<category>
		<pattern>* WHEN * CLOSED-WORLD ASSUMPTION * MODEL * PREFERRED * ANOTHER *</pattern>
		<template>For the closed-world assumption, one model is preferred to another if it has fewer true atoms.
 that is, preferred models are minimal models.</template>
	</category>
	<category>
		<pattern>* WHAT * NIXON DIAMOND *</pattern>
		<template>The standard example for which multiple inheritance is problematic is called the Nixon diamond.</template>
	</category>
	<category>
		<pattern>* NIXON DIAMOND * ARISES *</pattern>
		<template>It arises from the observation that Richard Nixon was both a Quaker (and hence by default a pacifist) and a Republican (and hence by default not a pacifist).</template>
	</category>
	<category>
		<pattern>* WHEN * USE * PRIORITIZED CIRCUMSCRIPTION *</pattern>
		<template>Prioritized schemes exist in which some default rules can be given precedence over others, allowing some ambiguities to be resolved.
 For example to assert that religious beliefs take precedence over political beliefs, we can use a formalism called prioritized circumscription.</template>
	</category>
	<category>
		<pattern>* GIVE * EXAMPLE * MODEL PREFERENCE LOGIC *</pattern>
		<template>Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* WHAT * EXAMPLE * MODEL PREFERENCE LOGIC *</pattern>
		<template>Circumscription can be viewed as an example of a model preference logic.</template>
	</category>
	<category>
		<pattern>* WHAT * DEFAULT LOGIC *</pattern>
		<template>Default logic is a formalism in which default rules can be written to generate continuous nonmonotonic conclusions and it is given by P : J1, .
 .
 .
 , Jn/C , where P is called the prerequisite, C is the conclusion, and Ji are the justifications.</template>
	</category>
	<category>
		<pattern>* WHAT * DEFAULT LOGIC * CONSIST *</pattern>
		<template>P : J1, .
 .
 .
 , Jn/C Where P is called the prerequisite, C is the conclusion, and Ji are the justifications, if any one of them can be proven false, then the conclusion cannot be drawn.
 Any variable that appears in Ji or C must also appear in P.</template>
	</category>
	<category>
		<pattern>* WHAT * EXTENSION * DEFAULT THEORY *</pattern>
		<template>We define the notion of an extension of a default theory to be a maximal set of consequences of the theory.</template>
	</category>
	<category>
		<pattern>* DEFINE * EXTENSION * DEFAULT THEORY *</pattern>
		<template>We define the notion of an extension of a default theory to be a maximal set of consequences of the theory.</template>
	</category>
	<category>
		<pattern>* WHAT * EXTENSION *</pattern>
		<template>We define the notion of an extension of a default theory to be a maximal set of consequences of the theory.</template>
	</category>
	<category>
		<pattern>* DEFINE * EXTENSION *</pattern>
		<template>We define the notion of an extension of a default theory to be a maximal set of consequences of the theory.</template>
	</category>
	<category>
		<pattern>* EXTENSION * CONSISTS *</pattern>
		<template>An extension S consists of the original known facts and a set of conclusions from the default rules, such that no additional conclusions can be drawn from S and the justifications of every default conclusion in S are consistent with S.</template>
	</category>
	<category>
		<pattern>* PRIORITIZED SCHEMES * EXIST *</pattern>
		<template>Prioritized schemes exist in which some default rules can be given precedence over others, allowing some ambiguities to be resolved.</template>
	</category>
	<category>
		<pattern>* WHEN * NONMONOTONIC LOGICS * PROPOSED *</pattern>
		<template>Since 1980.</template>
	</category>
	<category>
		<pattern>* WHEN * PROBLEM * NONMODULARITY *</pattern>
		<template>If we cannot decide, for each rule separately, whether it belongs in our knowledge base.</template>
	</category>
	<category>
		<pattern>* WHAT * HARDEST * ISSUE * DEFAULT REASONING *</pattern>
		<template>How can beliefs that have default status be used to make decisions is the hardest issue for default reasoning.</template>
	</category>
	<category>
		<pattern>* WHY * COMPARE * STRENGTHS * BELIEF * OUTCOMES * DIFFERENT * ACTIONS * COSTS * WRONG * DECISION *</pattern>
		<template>Because decisions often involve tradeoffs.</template>
	</category>
	<category>
		<pattern>* WHY * COMPARE * COSTS * WRONG * DECISION *</pattern>
		<template>Because decisions often involve tradeoffs.</template>
	</category>
	<category>
		<pattern>* WHY * COMPARE * STRENGTHS * BELIEF * OUTCOMES * DIFFERENT * ACTIONS *</pattern>
		<template>Because decisions often involve tradeoffs.</template>
	</category>
	<category>
		<pattern>* DECISIONS * INVOLVE * TRADEOFFS *</pattern>
		<template>One needs to compare the strengths of belief in the outcomes of different actions, and the costs of making a wrong decision.</template>
	</category>
	<category>
		<pattern>* SAME * DECISIONS * MADE * REPEATEDLY *</pattern>
		<template>It is possible to interpret default rules as "threshold probability" statements.</template>
	</category>
	<category>
		<pattern>* WHEN * THRESHOLD PROBABILITY *</pattern>
		<template>In cases where the same kinds of decisions are being made repeatedly.</template>
	</category>
	<category>
		<pattern>* EXAMPLE * THRESHOLD PROBABILITY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes.
 for example, when one is driving a heavily laden truck down a steep mountain road.
 the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* DEFAULT REASONING * PROBABILITY THEORY * UTILITY THEORY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes.
 for example, when one is driving a heavily laden truck down a steep mountain road.
 the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* DEFAULT REASONING * PROBABILITY THEORY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes.
 for example, when one is driving a heavily laden truck down a steep mountain road.
 the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* DEFAULT REASONING * UTILITY THEORY *</pattern>
		<template>For example, the default rule "My brakes are always OK" really means "The probability that my brakes are OK, given no other information, is sufficiently high that the optimal decision is for me to drive without checking them." When the decision context changes.
 for example, when one is driving a heavily laden truck down a steep mountain road.
 the default rule suddenly becomes inappropriate, even though there is no new evidence of faulty brakes.
 These considerations have led some researchers to consider how to embed default reasoning within probability theory or utility theory.</template>
	</category>
	<category>
		<pattern>* WHAT * BELIEF REVISION *</pattern>
		<template>Many of the inferences drawn by a knowledge representation system will have only default status, rather than being absolutely certain.
 Inevitably, some of these inferred facts will turn out to be wrong and will have to be retracted in the face of new information and this process is called belief revision.</template>
	</category>
	<category>
		<pattern>* WHEN * BELIEF UPDATE *</pattern>
		<template>It occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.</template>
	</category>
	<category>
		<pattern>* BELIEF REVISION * CONTRAST * BELIEF UPDATE *</pattern>
		<template>Belief revision is often contrasted with belief update, which occurs when a knowledge base is revised to reflect a change in the world rather than new information about a fixed world.
 Belief update combines belief revision with reasoning about time and change.</template>
	</category>
	<category>
		<pattern>* WHY * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>Truth maintenance systems are designedto handle exactly some kinds of complications suach as : For example, the implication P ? Q might have been used to add Q.
 The obvious "solution".
 retracting all sentences inferred from P fails because such sentences may have other justifications besides P.
 For example, if R and R ? Q are also in the KB, then Q does not have to be removed after all.</template>
	</category>
	<category>
		<pattern>* WHY * TMS *</pattern>
		<template>Truth maintenance systems are designedto handle exactly some kinds of complications suach as : For example, the implication P ? Q might have been used to add Q.
 The obvious "solution".
 retracting all sentences inferred from P fails because such sentences may have other justifications besides P.
 For example, if R and R ? Q are also in the KB, then Q does not have to be removed after all.</template>
	</category>
	<category>
		<pattern>* APPROACH * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>One simple approach to truth maintenance is to keep track of the order in which sentences are told to the knowledge base by numbering them from P1 to Pn.
 When the call RETRACT(KB, Pi) is made, the system reverts to the state just before Pi was added, thereby removing both Pi and any inferences that were derived from Pi.
 The sentences Pi+1 through Pn can then be added again.
 This is simple, and it guarantees that the knowledge base will be consistent.</template>
	</category>
	<category>
		<pattern>* EFFICIENT * APPROACH * TRUTH MAINTENANCE SYSTEM *</pattern>
		<template>An efficient approach JTMS is the justification-based truth maintenance system, or JTMS.
 In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.</template>
	</category>
	<category>
		<pattern>* WHAT * JTMS *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.</template>
	</category>
	<category>
		<pattern>* WHAT * JUSTIFICATION-BASED TRUTH * MAINTENANCE SYSTEM *</pattern>
		<template>In a JTMS, each sentence in the knowledge base is annotated with a justification consisting of the set of sentences from which it was inferred.</template>
	</category>
	<category>
		<pattern>* WHAH * JUSTIFICATION-BASED TRUTH * MAINTENANCE SYSTEM * ASSUME *</pattern>
		<template>The JTMS assumes that sentences that are considered once will probably be considered again, so rather than deleting a sentence from the knowledge base entirely when it loses all justifications, we merely mark the sentence as being out of the knowledge base.</template>
	</category>
	<category>
		<pattern>* WHAT * JTMS * ASSUME *</pattern>
		<template>The JTMS assumes that sentences that are considered once will probably be considered again, so rather than deleting a sentence from the knowledge base entirely when it loses all justifications, we merely mark the sentence as being out of the knowledge base.</template>
	</category>
	<category>
		<pattern>* HOW * JTMS * RETAIN * INFERENCE CHAINS *</pattern>
		<template>If a subsequent assertion restores one of the justifications, then we mark the sentence as being back in, and n this way, the JTMS retains all the inference chains that it uses and need not rederive sentences when a justification becomes valid again.</template>
	</category>
	<category>
		<pattern>* HOW * JUSTIFICATION-BASED TRUTH * MAINTENANCE SYSTEM * RETAIN * INFERENCE CHAINS *</pattern>
		<template>If a subsequent assertion restores one of the justifications, then we mark the sentence as being back in, and n this way, the JTMS retains all the inference chains that it uses and need not rederive sentences when a justification becomes valid again.</template>
	</category>
	<category>
		<pattern>* WHAT * TMS * HANDLE *</pattern>
		<template>It handles the retraction of incorrect information also TMSs can be used to speed up the analysis of multiple hypothetical situations, as it provides a mechanism for generating explanations.</template>
	</category>
	<category>
		<pattern>* WHAT * TMSS * HANDLE *</pattern>
		<template>It handles the retraction of incorrect information also TMSs can be used to speed up the analysis of multiple hypothetical situations, as it provides a mechanism for generating explanations.</template>
	</category>
	<category>
		<pattern>* WHAT * TRUTH MAINTENANCE SYSTEM * HANDLE *</pattern>
		<template>It handles the retraction of incorrect information also TMSs can be used to speed up the analysis of multiple hypothetical situations, as it provides a mechanism for generating explanations.</template>
	</category>
	<category>
		<pattern>* WHAT * ATMS *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* WHAT * ATMSS *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* WHAT * ASSUMPTION-BASED TRUTH * MAINTENANCE SYSTEM *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* WHAT * ASSUMPTION-BASED TRUTH * MAINTENANCE SYSTEM *</pattern>
		<template>An assumption-based truth ATMS maintenance system, or ATMS, makes this type of contextswitching between hypothetical worlds particularly efficient.
 An ATMS represents all the states that have ever been considered at the same time.
 Whereas a JTMS simply labels each sentence as being in or out, an ATMS keeps track, for each sentence, of which assumptions would cause the sentence to be true.
 In other words, each sentence has a label that consists of a set of assumption sets.</template>
	</category>
	<category>
		<pattern>* EXPLANATION * SENTENCE *</pattern>
		<template>Technically, an explanation of a sentence P is a set of sentences E such that E entails P.</template>
	</category>
	<category>
		<pattern>* EXPLANATIONS * INCLUDE * ASSUMPTIONS *</pattern>
		<template>For example, one might not have enough information to prove that one's car won't start, but a reasonable explanation might include the assumption that the battery is dead.
 This, combined with knowledge of how cars operate, explains the observed nonbehavior.</template>
	</category>
	<category>
		<pattern>* COMPLEXITY * TRUTH MAINTENANCE SYSTEMS *</pattern>
		<template>The computational complexity of the truth maintenance problem is at least as great as that of propositional inference.
 that is, NP-hard.</template>
	</category>
	<category>
		<pattern>* COMPLEXITY * TMS *</pattern>
		<template>The computational complexity of the truth maintenance problem is at least as great as that of propositional inference.
 that is, NP-hard.</template>
	</category>
	<category>
		<pattern>* REASONING SYSTEMS * CATEGORIES *</pattern>
		<template>Reasoning systems Categories are the primary building blocks of large-scale knowledge representation schemes.</template>
	</category>
	<category>
		<pattern>* CATEGORIES * REASONING SYSTEMS *</pattern>
		<template>Reasoning systems Categories are the primary building blocks of large-scale knowledge representation schemes.</template>
	</category>
	<category>
		<pattern>* WHAT * PRIMARY * BLOCKS * KNOWLEDGE REPRESENTATION *</pattern>
		<template>Categories are the primary building blocks of large-scale knowledge representation schemes.</template>
	</category>
	<category>
		<pattern>* FAMILIES * REASONING SYSTEMS *</pattern>
		<template>There are two closely related families of systems: semantic networks and description logics.</template>
	</category>
	<category>
		<pattern>* WHAT ARE SEMANTIC NETWORKS *</pattern>
		<template>Semantic networks provide graphical aids for visualizing a knowledge base and efficient algorithms for inferring properties of an object on the basis of its category membership.</template>
	</category>
	<category>
		<pattern>* DEFINE * SEMANTIC NETWORKS *</pattern>
		<template>Semantic networks provide graphical aids for visualizing a knowledge base and efficient algorithms for inferring properties of an object on the basis of its category membership.</template>
	</category>
	<category>
		<pattern>* WHAT * SEMANTIC NETWORKS PROVIDE *</pattern>
		<template>Semantic networks provide graphical aids for visualizing a knowledge base and efficient algorithms for inferring properties of an object on the basis of its category membership.</template>
	</category>
	<category>
		<pattern>* WHAT ARE DESCRIPTION LOGICS *</pattern>
		<template>Description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* WHAT * DESCRIPTION LOGICS PROVIDE *</pattern>
		<template>Description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* DEFINE * DESCRIPTION LOGICS *</pattern>
		<template>Description logics provide a formal language for constructing and combining category definitions and efficient algorithms for deciding subset and superset relationships between categories.</template>
	</category>
	<category>
		<pattern>* WHAT * CHARLES * PROPOSE *</pattern>
		<template>In 1909, Charles S.
 Peirce proposed a graphical notation of nodes and edges called existential graphs.</template>
	</category>
	<category>
		<pattern>* WHAT * PEIRCE * PROPOSE *</pattern>
		<template>In 1909, Charles S.
 Peirce proposed a graphical notation of nodes and edges called existential graphs.</template>
	</category>
	<category>
		<pattern>* WHEN * EXESTENIAL GRAPHS *</pattern>
		<template>In 1909, Charles S.
 Peirce proposed a graphical notation of nodes and edges called existential graphs.</template>
	</category>
	<category>
		<pattern>* WHAT * EXESTENIAL GRAPHS *</pattern>
		<template>A graphical notation of nodes and edges that was called "the logic of the future."</template>
	</category>
	<category>
		<pattern>* DEFINE * EXESTENIAL GRAPHS *</pattern>
		<template>A graphical notation of nodes and edges that was called "the logic of the future."</template>
	</category>
	<category>
		<pattern>* DEBATE * EXESTENIAL GRAPHS *</pattern>
		<template>Thus began a long-running debate between advocates of "logic" and advocates of "semantic networks." Unfortunately, the debate obscured the fact that semantics networks at least those with well-defined semantics are a form of logic.</template>
	</category>
	<category>
		<pattern>* SEMANTIC NETWORKS * LOGIC *</pattern>
		<template>The notation that semantic networks provide for certain kinds of sentences is often more convenient, but if we strip away the "human interface" issues, the underlying concepts objects, relations, quantification, and so on are the same.</template>
	</category>
	<category>
		<pattern>* WHAT * SEMANTIC NETWORKS * REPRESENT *</pattern>
		<template>There are many variants of semantic networks, but all are capable of representing individual objects, categories of objects, and relations among objects.</template>
	</category>
	<category>
		<pattern>* WHAT * TYPICAL GRAPHICAL * SEMANTIC * DISPLAY *</pattern>
		<template>A typical graphical notation displays object or category names in ovals or boxes, and connects them with labeled links.</template>
	</category>
	<category>
		<pattern>* DOUBLE BOXED *</pattern>
		<template>A special notation for the semantic networks.
 For example, we know that persons have female persons as mothers, so can we draw a HasMother link from Persons to FemalePersons? The answer is no, because HasMother is a relation between a person and his or her mother, and categories do not have mothers.</template>
	</category>
	<category>
		<pattern>* SINGLE BOXED *</pattern>
		<template>the single-boxed link is used to assert properties of every member of a category.</template>
	</category>
	<category>
		<pattern>* HOW * SEMANTIC NETWORKS * INHERITANCE *</pattern>
		<template>By virtue of being a person, Mary inherits the property of having two legs.
 Thus, to find out how many legs Mary has, the inheritance algorithm follows the MemberOf link from Mary to the category she belongs to, and then follows SubsetOf links up the hierarchy until it finds a category for which there is a boxed Legs link in this case, the Persons category.</template>
	</category>
	<category>
		<pattern>* ATTRACTIONS * SEMANTIC NETWORKS *</pattern>
		<template>The simplicity and efficiency of this inference mechanism, compared with logical theorem proving, has been one of the main attractions of semantic networks.</template>
	</category>
	<category>
		<pattern>* WHEN * INHERITANCE * COMPLICATED *</pattern>
		<template>Inheritance becomes complicated when an object can belong to more than one category or when a category can be a subset of more than one other category.</template>
	</category>
	<category>
		<pattern>* WHAT * MULTIPLE INHERITANCE *</pattern>
		<template>Multiple inheritance is when an object can belong to more than one category or when a category can be a subset of more than one other category.</template>
	</category>
	<category>
		<pattern>* DEFINE * MULTIPLE INHERITANCE *</pattern>
		<template>Multiple inheritance is when an object can belong to more than one category or when a category can be a subset of more than one other category.</template>
	</category>
	<category>
		<pattern>* WHY * MULTIPLE * INHERITANCE * BANNED *</pattern>
		<template>The inheritance algorithm might find two or more conflicting values answering the query.
 For this reason, multiple inheritance is banned in some object oriented programming (OOP) languages, such as Java</template>
	</category>
	<category>
		<pattern>* WHAT * DRAWBACK * SEMANTIC NETWORKS * FIRST-ORDER LOGIC *</pattern>
		<template>The fact that links between bubbles represent only binary relations.
 For example, the sentence Fly(Shankar, NewYork, NewDelhi, Yesterday) cannot be asserted directly in a semantic network.</template>
	</category>
	<category>
		<pattern>* HOW * N-ARY ASSERTIONS *</pattern>
		<template>We can obtain the effect of n-ary assertions by reifying the proposition itself as an event belonging to an appropriate event category.</template>
	</category>
	<category>
		<pattern>* WHAT * RESTRICTION * BINARY RELATIONS *</pattern>
		<template>The restriction to binary relations forces the creation of a rich ontology of reified concepts.</template>
	</category>
	<category>
		<pattern>* REIFICTION * PROPOSITIONS *</pattern>
		<template>Reification of propositions makes it possible to represent every ground, function free atomic sentence of first order logic in the semantic network notation.</template>
	</category>
	<category>
		<pattern>* HOW * UNIVERSALLY QUALIFIED * ASSERTED *</pattern>
		<template>Certain kinds of universally quantified sentences can be asserted using inverse links and the singly boxed and doubly boxed arrows applied to categories.</template>
	</category>
	<category>
		<pattern>* MISSING * FIRST-ORDER * SEMANTIC *</pattern>
		<template>Negation, disjunction, nested function symbols, and existential quantification are all missing.</template>
	</category>
	<category>
		<pattern>* HOW * SEMANTIC NETWORKS * EQUIVILANT * FIRST-ORDER *</pattern>
		<template>It is possible to extend the notation to make it equivalent to first-order logic as in Peirce's existential graphs but doing so negates one of the main advantages of semantic networks, which is the simplicity and transparency of the inference processes.</template>
	</category>
	<category>
		<pattern>* EXTEND NOTATION * SEMANTIC NETWORKS *</pattern>
		<template>It is possible to extend the notation to make it equivalent to first-order logic as in Peirce's existential graphs but doing so negates one of the main advantages of semantic networks, which is the simplicity and transparency of the inference processes.</template>
	</category>
	<category>
		<pattern>* NOTATION EXTENSION * SEMANTIC NETWORKS *</pattern>
		<template>It is possible to extend the notation to make it equivalent to first-order logic as in Peirce's existential graphs but doing so negates one of the main advantages of semantic networks, which is the simplicity and transparency of the inference processes.</template>
	</category>
	<category>
		<pattern>* ADVANTAGE * SEMANTIC NETWORKS *</pattern>
		<template>The simplicity and transparency of the inference processes.</template>
	</category>
	<category>
		<pattern>* WHY * LARGE NETWORKS * QUERIES * EFFICIENT *</pattern>
		<template>because (a) it is easy to visualize the steps that the inference procedure will go through and (b) in some cases the query language is so simple that difficult queries cannot be posed.</template>
	</category>
	<category>
		<pattern>* WHEN * SEMANTIC NETWORKS * PROCEDURAL ATTACHMENT *</pattern>
		<template>In cases where the expressive power proves to be too limiting, many semantic network systems provide for procedural attachment to fill in the gaps.</template>
	</category>
	<category>
		<pattern>* WHAT * SEMANTIC NETWORKS * FILL * GAPS *</pattern>
		<template>Many semantic network systems provide for procedural attachment to fill in the gaps</template>
	</category>
	<category>
		<pattern>* WHAT * PROCEDURAL ATTACHMENT *</pattern>
		<template>Procedural attachment is a technique whereby a query about (or sometimes an assertion of) a certain relation results in a call to a special procedure designed for that relation rather than a general inference algorithm.</template>
	</category>
	<category>
		<pattern>* DEFINE * PROCEDURAL ATTACHMENT *</pattern>
		<template>Procedural attachment is a technique whereby a query about (or sometimes an assertion of) a certain relation results in a call to a special procedure designed for that relation rather than a general inference algorithm.</template>
	</category>
	<category>
		<pattern>* WHAT * IMPORTANT * SEMANTIC NETWORKS *</pattern>
		<template>One of the most important aspects of semantic networks is their ability to represent default values for categories.</template>
	</category>
	<category>
		<pattern>* OVERRIDING * DEFAULT VALUES *</pattern>
		<template>The default semantics is enforced naturally by the inheritance algorithm, because it follows links upwards from the object itself (John in this case) and stops as soon as it finds a value.
 We say that the default is overridden by the more specific value.</template>
	</category>
	<category>
		<pattern>* WHAT * FULL-ORDER * DESIGN *</pattern>
		<template>The syntax of first-order logic is designed to make it easy to say things about objects.</template>
	</category>
	<category>
		<pattern>* WHAT * DESCRIPTION LOGICS * DESIGN *</pattern>
		<template>Description logics are notations that are designed to make it easier to describe definitions and properties of categories.</template>
	</category>
	<category>
		<pattern>* COMPARE * FULL-ORDER * DESCRIPTION LOGICS *</pattern>
		<template>The syntax of first-order logic is designed to make it easy to say things about objects.
 Description logics are notations that are designed to make it easier to describe definitions and properties of categories.
 The description logic has an an algebra of operations on predicates, which of course we can't do in first-order logic.
 Any description in C LASSIC can be translated into an equivalent first-order sentence, but some descriptions are more straightforward in CLASSIC.</template>
	</category>
	<category>
		<pattern>* HOW * DESCRIPTION LOGIC * EVOLVE *</pattern>
		<template>Description logic systems evolved from semantic networks in response to pressure to formalize what the networks mean while retaining the emphasis on taxonomic structure as an organizing principle.</template>
	</category>
	<category>
		<pattern>* WHAT * PRINCIPAL INFERENCE * DESCRIPTION LOGICS *</pattern>
		<template>The principal inference tasks for description logics are subsumption, classification, and Some systems also include consistency of a category definition.</template>
	</category>
	<category>
		<pattern>* SUBSUMPTION *</pattern>
		<template>checking if one category is a subset of another by comparing their definitions.</template>
	</category>
	<category>
		<pattern>* CLASSIFICATION *</pattern>
		<template>checking whether an object belongs to a category.</template>
	</category>
	<category>
		<pattern>* CONSISTENCY * CATEGORY *</pattern>
		<template>checking whether the membership criteria are logically satisfiable.</template>
	</category>
	<category>
		<pattern>* WHAT * CLASSIC * DESCRIPTION LOGIC *</pattern>
		<template>The CLASSIC language (Borgida et al., 1989) is a typical description logic.</template>
	</category>
	<category>
		<pattern>* WHAT * IMPORTANT * DESCRIPTION LOGICS *</pattern>
		<template>Perhaps the most important aspect of description logics is their emphasis on tractability of inference.</template>
	</category>
	<category>
		<pattern>* HOW * PROBLEM INSTANCE *</pattern>
		<template>A problem instance is solved by describing it and then asking if it is subsumed by one of several possible solution categories.</template>
	</category>
	<category>
		<pattern>* FIRST-ORDER LOGIC * DESCRIPTION LOGICS * TIME *</pattern>
		<template>In standard first-order logic systems, predicting the solution time is often impossible.
 It is frequently left to the user to engineer the representation to detour around sets of sentences that seem to be causing the system to take several weeks to solve a problem.
 The thrust in description logics, on the other hand, is to ensure that subsumption testing can be solved in time polynomial in the size of the descriptions.</template>
	</category>
	<category>
		<pattern>* CONSEQUENCES * PROBLEM *</pattern>
		<template>It can only have one of two consequences: either hard problems cannot be stated at all, or they require exponentially large descriptions!</template>
	</category>
	<category>
		<pattern>* TRACTABILITY RESULTS *</pattern>
		<template>The tractability results do shed light on what sorts of constructs cause problems and thus help the user to understand how different representations behave.</template>
	</category>
	<category>
		<pattern>* WHAT * DESCRIPTION LOGICS * LACK *</pattern>
		<template>Description logics usually lack negation and disjunction.</template>
	</category>
	<category>
		<pattern>* DISADVANTAGES * DESCRIPTION LOGICS *</pattern>
		<template>Description logics usually lack negation and disjunction.</template>
	</category>
	<category>
		<pattern>* HOW * DESCRIPTION LOGIC * DISJUNCTION *</pattern>
		<template>CLASSIC allows only a limited form of disjunction in the Fills and One Of constructs, which permit disjunction over explicitly enumerated individuals but not over descriptions.</template>
	</category>
	<category>
		<pattern>* WHAT * DESCRIPTION LOGICS * NESTED DEFINITION *</pattern>
		<template>With disjunctive descriptions, nested definitions can lead easily to an exponential number of alternative routes by which one category can subsume another.</template>
	</category>

	<!-- Synomyns -->
	<category>
		<pattern>* DEFINE *</pattern>
		<template>
			<srai><star index="1"/> WHAT <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* DESCRIBE *</pattern>
		<template>
			<srai><star index="1"/> WHAT <star index="2"/></srai>
			<srai><star index="1"/> EXPLAIN <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* DISCUSS *</pattern>
		<template>
			<srai><star index="1"/> WHAT <star index="2"/></srai>
			<srai><star index="1"/> EXPLAIN <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* MENTION *</pattern>
		<template>
			<srai><star index="1"/> GIVE <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* LIST *</pattern>
		<template>
			<srai><star index="1"/> GIVE <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* EXAMPLE *</pattern>
		<template>
			<srai><star index="1"/> GIVE <star index="2"/></srai>
			<srai><star index="1"/> GIVE <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* GIVE *</pattern>
		<template>
			<srai><star index="1"/> EXAMPLE <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* WHAT *</pattern>
		<template>
			<srai><star index="1"/> EXPLAIN <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* WHY *</pattern>
		<template>
			<srai><star index="1"/> EXPLAIN <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* HOW *</pattern>
		<template>
			<srai><star index="1"/> EXPLAIN <star index="2"/></srai>
		</template>
	</category>
	<category>
		<pattern>* EXPLAIN *</pattern>
		<template>
			<srai><star index="1"/> WHY <star index="2"/></srai>
		</template>
	</category>
</aiml>